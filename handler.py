import runpod
import os
import base64
import numpy as np
from io import BytesIO
from PIL import Image, ImageEnhance, ImageFilter
import requests
import logging
import re
import replicate
import string
import cv2

logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger(__name__)

VERSION = "V3-Light-Gray-Shadow"

# ===== REPLICATE INITIALIZATION =====
REPLICATE_API_TOKEN = os.environ.get('REPLICATE_API_TOKEN')
REPLICATE_CLIENT = None
USE_REPLICATE = False

if REPLICATE_API_TOKEN:
    try:
        REPLICATE_CLIENT = replicate.Client(api_token=REPLICATE_API_TOKEN)
        USE_REPLICATE = True
        logger.info("‚úÖ Replicate client initialized")
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize Replicate: {e}")
        USE_REPLICATE = False

def find_input_data_fast(data):
    """Fast input data extraction"""
    if isinstance(data, str) and len(data) > 50:
        return {'image': data}
    
    if isinstance(data, dict):
        # Priority keys
        priority_keys = ['image', 'image_base64', 'enhanced_image', 'base64', 'img']
        
        for key in priority_keys:
            if key in data and isinstance(data[key], str) and len(data[key]) > 50:
                return {key: data[key]}
        
        # Check nested (limited depth)
        for key in ['input', 'data']:
            if key in data and isinstance(data[key], dict):
                result = find_input_data_fast(data[key])
                if result:
                    return result
        
        # Numeric keys (Make.com)
        for i in range(5):
            if str(i) in data and isinstance(data[str(i)], str) and len(data[str(i)]) > 50:
                return {'image': data[str(i)]}
    
    return data

def find_filename_fast(data):
    """Fast filename extraction"""
    if isinstance(data, dict):
        for key in ['filename', 'file_name', 'name']:
            if key in data and isinstance(data[key], str):
                return data[key]
        
        # Check nested once
        if 'input' in data and isinstance(data['input'], dict):
            for key in ['filename', 'file_name', 'name']:
                if key in data['input']:
                    return data['input'][key]
    
    return None

def generate_thumbnail_filename(original_filename, image_index):
    """Generate thumbnail filename"""
    if not original_filename:
        return f"thumbnail_{image_index:03d}.jpg"
    
    thumbnail_numbers = {1: "007", 3: "008", 5: "009"}
    
    new_filename = original_filename
    pattern = r'(_\d{3})'
    if re.search(pattern, new_filename):
        new_filename = re.sub(pattern, f'_{thumbnail_numbers.get(image_index, "007")}', new_filename)
    else:
        name_parts = new_filename.split('.')
        name_parts[0] += f'_{thumbnail_numbers.get(image_index, "007")}'
        new_filename = '.'.join(name_parts)
    
    return new_filename

def base64_to_image_fast(base64_string):
    """Fast base64 to image conversion - PNG support"""
    try:
        if not base64_string or len(base64_string) < 50:
            raise ValueError("Invalid base64")
        
        # Quick clean
        if 'base64,' in base64_string:
            base64_string = base64_string.split('base64,')[-1]
        
        # Remove whitespace
        base64_string = ''.join(base64_string.split())
        
        # Keep only valid chars
        valid_chars = set(string.ascii_letters + string.digits + '+/=')
        base64_string = ''.join(c for c in base64_string if c in valid_chars)
        
        # Try without padding first (Make.com)
        no_pad = base64_string.rstrip('=')
        
        try:
            img_data = base64.b64decode(no_pad, validate=False)
            return Image.open(BytesIO(img_data))
        except:
            # Try with correct padding
            padding = (4 - len(no_pad) % 4) % 4
            padded = no_pad + ('=' * padding)
            img_data = base64.b64decode(padded, validate=False)
            return Image.open(BytesIO(img_data))
            
    except Exception as e:
        logger.error(f"Base64 decode error: {str(e)}")
        raise ValueError(f"Invalid base64: {str(e)}")

def detect_pattern_type(filename: str) -> str:
    """Detect pattern type - SIMPLIFIED to ac_ and others"""
    if not filename:
        return "other"
    
    filename_lower = filename.lower()
    
    # Only ac_ is special (Î¨¥ÎèÑÍ∏àÌôîÏù¥Ìä∏)
    if 'ac_' in filename_lower:
        return "ac_pattern"
    else:
        return "other"

def create_background(size, color="#F0F0F0", style="gradient"):
    """Create natural light gray background for jewelry"""
    width, height = size
    
    if style == "gradient":
        # Create radial gradient background
        background = Image.new('RGB', size, color)
        bg_array = np.array(background, dtype=np.float32)
        
        # Create radial gradient
        y, x = np.ogrid[:height, :width]
        center_x, center_y = width / 2, height / 2
        distance = np.sqrt((x - center_x)**2 + (y - center_y)**2) / max(width, height)
        
        # Very subtle gradient for natural look
        gradient = 1 - (distance * 0.05)  # Only 5% darkening at edges
        gradient = np.clip(gradient, 0.95, 1.0)
        
        # Apply gradient
        bg_array *= gradient[:, :, np.newaxis]
        
        return Image.fromarray(bg_array.astype(np.uint8))
    else:
        return Image.new('RGB', size, color)

def remove_background_with_replicate(image: Image.Image) -> Image.Image:
    """Remove background using Replicate API - AGGRESSIVE FOR RING HOLES"""
    if not USE_REPLICATE or not REPLICATE_CLIENT:
        logger.warning("Replicate not available for background removal")
        return image
    
    try:
        logger.info("üî∑ Removing background with Replicate (aggressive mode)")
        
        # Convert to base64
        buffered = BytesIO()
        image.save(buffered, format="PNG")
        buffered.seek(0)
        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
        img_data_url = f"data:image/png;base64,{img_base64}"
        
        # Use rembg model with AGGRESSIVE settings
        output = REPLICATE_CLIENT.run(
            "cjwbw/rembg:fb8af171cfa1616ddcf1242c093f9c46bcada5ad4cf6f2fbe8b81b330ec5c003",
            input={
                "image": img_data_url,
                "model": "u2net",  # Back to u2net for better hole detection
                "alpha_matting": True,
                "alpha_matting_foreground_threshold": 270,  # Higher for aggressive
                "alpha_matting_background_threshold": 10,    # Very low for holes
                "alpha_matting_erode_size": 10              # Larger for cleaner edges
            }
        )
        
        if output:
            if isinstance(output, str):
                response = requests.get(output)
                result_image = Image.open(BytesIO(response.content))
            else:
                result_image = Image.open(BytesIO(base64.b64decode(output)))
            
            logger.info("‚úÖ Background removal successful")
            return result_image
        else:
            logger.warning("No output from background removal")
            return image
            
    except Exception as e:
        logger.error(f"Background removal error: {str(e)}")
        return image

def add_natural_edge_feathering(image: Image.Image) -> Image.Image:
    """Add MORE natural feathering to edges for thumbnails"""
    if image.mode != 'RGBA':
        return image
    
    # Get alpha channel
    r, g, b, a = image.split()
    
    # Apply stronger Gaussian blur to alpha channel
    a_array = np.array(a, dtype=np.float32)
    
    # Create edge mask
    edges = cv2.Canny(a_array.astype(np.uint8), 30, 100)  # Lower thresholds
    
    # Dilate edges more for thumbnails
    kernel = np.ones((3, 3), np.uint8)  # Smaller kernel for thumbnails
    edges_dilated = cv2.dilate(edges, kernel, iterations=1)
    
    # Apply Gaussian blur to edges
    edge_blur = cv2.GaussianBlur(edges_dilated.astype(np.float32), (7, 7), 2.0)  # Adjusted for thumbnail
    
    # Blend original alpha with blurred edges
    alpha_feathered = np.where(edge_blur > 0, 
                               a_array * 0.85 + edge_blur * 0.15,  # Slightly less feathering
                               a_array)
    
    # Apply overall blur to alpha for smoothness
    alpha_final = cv2.GaussianBlur(alpha_feathered, (3, 3), 0.8)
    
    # Create new image with feathered alpha
    a_new = Image.fromarray(alpha_final.astype(np.uint8))
    return Image.merge('RGBA', (r, g, b, a_new))

def composite_with_light_gray_background(image, background_color="#F0F0F0"):
    """Natural composite with light gray background - FIXED for ring holes"""
    if image.mode == 'RGBA':
        # Apply strong edge feathering first
        image = add_natural_edge_feathering(image)
        
        # Create background
        background = create_background(image.size, background_color, style="gradient")
        
        # Get alpha channel
        alpha = image.split()[3]
        
        # Create very soft shadows with LIGHT GRAY
        shadow_array = np.array(alpha, dtype=np.float32) / 255.0
        
        # Layer 1: Very soft contact shadow (smaller for thumbnails)
        shadow1 = cv2.GaussianBlur(shadow_array, (7, 7), 2)
        shadow1 = (shadow1 * 0.03 * 255).astype(np.uint8)  # Very subtle 3%
        
        # Layer 2: Diffuse shadow
        shadow2 = cv2.GaussianBlur(shadow_array, (15, 15), 4)
        shadow2 = (shadow2 * 0.02 * 255).astype(np.uint8)  # 2% opacity
        
        # Layer 3: Ambient occlusion
        shadow3 = cv2.GaussianBlur(shadow_array, (25, 25), 7)
        shadow3 = (shadow3 * 0.01 * 255).astype(np.uint8)  # Very subtle 1%
        
        # Composite shadows
        final_shadow = np.maximum(shadow1, np.maximum(shadow2, shadow3))
        
        # Create shadow image with minimal offset
        shadow_img = Image.fromarray(final_shadow, mode='L')
        shadow_offset = Image.new('L', image.size, 0)
        
        # Almost no offset (0.5 pixel for thumbnails)
        shadow_offset.paste(shadow_img, (1, 0))
        
        # Apply shadow to background - use light gray shadow
        # Light gray shadow color (instead of dark)
        shadow_color = (230, 230, 230)  # Very light gray
        
        shadow_layer = Image.new('RGB', image.size, shadow_color)
        background.paste(shadow_layer, mask=shadow_offset)
        
        # Final composite with proper alpha blending
        # Use premultiplied alpha for better edge quality
        r, g, b, a = image.split()
        
        # Premultiply RGB by alpha
        a_array = np.array(a, dtype=np.float32) / 255.0
        r_array = np.array(r, dtype=np.float32) * a_array
        g_array = np.array(g, dtype=np.float32) * a_array
        b_array = np.array(b, dtype=np.float32) * a_array
        
        # Convert background to array
        bg_array = np.array(background, dtype=np.float32)
        
        # Composite using proper alpha blending
        result_r = r_array + bg_array[:,:,0] * (1 - a_array)
        result_g = g_array + bg_array[:,:,1] * (1 - a_array)
        result_b = b_array + bg_array[:,:,2] * (1 - a_array)
        
        # Stack and convert back
        result = np.stack([result_r, result_g, result_b], axis=2)
        result = np.clip(result, 0, 255).astype(np.uint8)
        
        return Image.fromarray(result)
    else:
        return image

def apply_swinir_thumbnail_after_resize(image: Image.Image) -> Image.Image:
    """Apply SwinIR AFTER resize - NEW for thumbnails"""
    if not USE_REPLICATE or not REPLICATE_CLIENT:
        return image
    
    try:
        width, height = image.size
        
        # Only apply to thumbnail size
        if width > 1200 or height > 1500:
            logger.info(f"Skipping SwinIR - too large: {width}x{height}")
            return image
        
        logger.info(f"Applying SwinIR to thumbnail: {width}x{height}")
        
        # Convert to base64
        buffered = BytesIO()
        image.save(buffered, format="PNG", optimize=False)
        buffered.seek(0)
        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
        img_data_url = f"data:image/png;base64,{img_base64}"
        
        logger.info("üî∑ SwinIR thumbnail (post-resize)")
        
        output = REPLICATE_CLIENT.run(
            "jingyunliang/swinir:660d922d33153019e8c263a3bba265de882e7f4f70396546b6c9c8f9d47a021a",
            input={
                "image": img_data_url,
                "task_type": "Real-World Image Super-Resolution",
                "scale": 1,  # Keep size
                "noise_level": 10,
                "jpeg_quality": 50
            }
        )
        
        if output:
            if isinstance(output, str):
                response = requests.get(output)
                enhanced_image = Image.open(BytesIO(response.content))
            else:
                enhanced_image = Image.open(BytesIO(base64.b64decode(output)))
            
            return enhanced_image
            
    except Exception as e:
        logger.warning(f"SwinIR error: {str(e)}")
        
    return image

def enhance_cubic_details_thumbnail_simple(image: Image.Image) -> Image.Image:
    """Enhanced cubic details for thumbnails"""
    # Much stronger contrast
    contrast = ImageEnhance.Contrast(image)
    image = contrast.enhance(1.12)  # Increased from 1.08
    
    # Strong detail enhancement
    image = image.filter(ImageFilter.UnsharpMask(radius=0.4, percent=140, threshold=2))  # Increased
    
    # Additional micro-contrast
    contrast2 = ImageEnhance.Contrast(image)
    image = contrast2.enhance(1.05)  # Increased from 1.03
    
    # Extra sharpness
    sharpness = ImageEnhance.Sharpness(image)
    image = sharpness.enhance(1.3)  # Added
    
    return image

def auto_white_balance_fast(image: Image.Image) -> Image.Image:
    """Fast white balance"""
    img_array = np.array(image, dtype=np.float32)
    
    # Sample for speed
    sampled = img_array[::10, ::10]
    gray_mask = (
        (np.abs(sampled[:,:,0] - sampled[:,:,1]) < 15) & 
        (np.abs(sampled[:,:,1] - sampled[:,:,2]) < 15) &
        (sampled[:,:,0] > 180)
    )
    
    if np.sum(gray_mask) > 10:
        r_avg = np.mean(sampled[gray_mask, 0])
        g_avg = np.mean(sampled[gray_mask, 1])
        b_avg = np.mean(sampled[gray_mask, 2])
        
        gray_avg = (r_avg + g_avg + b_avg) / 3
        
        img_array[:,:,0] *= (gray_avg / r_avg) if r_avg > 0 else 1
        img_array[:,:,1] *= (gray_avg / g_avg) if g_avg > 0 else 1
        img_array[:,:,2] *= (gray_avg / b_avg) if b_avg > 0 else 1
    
    return Image.fromarray(np.clip(img_array, 0, 255).astype(np.uint8))

def apply_center_spotlight_fast(image: Image.Image, intensity: float = 0.04) -> Image.Image:
    """Fast center spotlight - Slightly increased"""
    width, height = image.size
    
    y, x = np.ogrid[:height, :width]
    center_x, center_y = width / 2, height / 2
    distance = np.sqrt((x - center_x)**2 + (y - center_y)**2) / max(width, height)
    
    spotlight_mask = 1 + intensity * np.exp(-distance**2 * 3)
    spotlight_mask = np.clip(spotlight_mask, 1.0, 1.0 + intensity)
    
    img_array = np.array(image, dtype=np.float32)
    img_array *= spotlight_mask[:, :, np.newaxis]
    
    return Image.fromarray(np.clip(img_array, 0, 255).astype(np.uint8))

def apply_wedding_ring_focus_fast(image: Image.Image) -> Image.Image:
    """Enhanced wedding ring focus for thumbnails"""
    # Slightly increased spotlight
    image = apply_center_spotlight_fast(image, 0.03)
    
    # Much stronger sharpness
    sharpness = ImageEnhance.Sharpness(image)
    image = sharpness.enhance(1.9)  # Increased from 1.7
    
    # Stronger contrast
    contrast = ImageEnhance.Contrast(image)
    image = contrast.enhance(1.06)  # Increased from 1.04
    
    # Strong multi-scale unsharp mask
    image = image.filter(ImageFilter.UnsharpMask(radius=1.0, percent=120, threshold=2))
    
    return image

def calculate_quality_metrics_fast(image: Image.Image) -> dict:
    """Fast quality metrics"""
    img_array = np.array(image)[::20, ::20]  # Sample
    
    r_avg = np.mean(img_array[:,:,0])
    g_avg = np.mean(img_array[:,:,1])
    b_avg = np.mean(img_array[:,:,2])
    
    brightness = (r_avg + g_avg + b_avg) / 3
    cool_tone_diff = b_avg - r_avg
    
    return {
        "brightness": brightness,
        "cool_tone_diff": cool_tone_diff
    }

def apply_pattern_enhancement_fast(image, pattern_type):
    """Fast pattern enhancement - 17% white overlay for ac_ (1Ï∞®)"""
    
    # Apply white overlay ONLY to ac_pattern (17% - increased from 12%)
    if pattern_type == "ac_pattern":
        # Unplated white - 17% white overlay (1Ï∞®: 12% ‚Üí 17%, 5% Ï¶ùÍ∞Ä)
        white_overlay = 0.17
        img_array = np.array(image, dtype=np.float32)
        img_array = img_array * (1 - white_overlay) + 255 * white_overlay
        img_array = np.clip(img_array, 0, 255)
        image = Image.fromarray(img_array.astype(np.uint8))
        
        # Reduced brightness for ac_
        brightness = ImageEnhance.Brightness(image)
        image = brightness.enhance(1.02)
        
        color = ImageEnhance.Color(image)
        image = color.enhance(0.96)
        
    else:
        # All other patterns - much stronger enhancement
        brightness = ImageEnhance.Brightness(image)
        image = brightness.enhance(1.12)  # Increased from 1.08
        
        color = ImageEnhance.Color(image)
        image = color.enhance(0.98)  # Slightly increased
        
        # Strong sharpness
        sharpness = ImageEnhance.Sharpness(image)
        image = sharpness.enhance(1.8)  # Increased from 1.6
    
    # Slightly increased spotlight
    image = apply_center_spotlight_fast(image, 0.04)
    
    # Wedding ring enhancement
    image = apply_wedding_ring_focus_fast(image)
    
    # Fast quality check (only for ac_pattern) - 2Ï∞® Ï≤òÎ¶¨
    if pattern_type == "ac_pattern":
        metrics = calculate_quality_metrics_fast(image)
        if metrics["brightness"] < 240:
            # Apply 20% white overlay as correction (2Ï∞®: 15% ‚Üí 20%, 5% Ï¶ùÍ∞Ä)
            white_overlay = 0.20
            img_array = np.array(image, dtype=np.float32)
            img_array = img_array * (1 - white_overlay) + 255 * white_overlay
            img_array = np.clip(img_array, 0, 255)
            image = Image.fromarray(img_array.astype(np.uint8))
    
    return image

def create_thumbnail_optimized(image, target_width=1000, target_height=1300):
    """Optimized thumbnail creation for 2000x2600 input"""
    original_width, original_height = image.size
    
    # Check if input is expected 2000x2600 ratio
    expected_ratio = 2000 / 2600  # 0.769
    actual_ratio = original_width / original_height
    
    if abs(actual_ratio - expected_ratio) < 0.01:
        # Perfect ratio match - direct resize to 1000x1300
        return image.resize((target_width, target_height), Image.Resampling.LANCZOS)
    else:
        # Different ratio - use existing logic
        logger.warning(f"Unexpected ratio: {original_width}x{original_height} ({actual_ratio:.3f})")
        
        # Fixed center
        image_center = (original_width // 2, original_height // 2)
        
        # Upscale if needed
        if original_width < target_width or original_height < target_height:
            scale_factor = max(target_width / original_width, target_height / original_height) * 1.1
            
            new_size = (int(original_width * scale_factor), int(original_height * scale_factor))
            image = image.resize(new_size, Image.Resampling.LANCZOS)
            image_center = (new_size[0] // 2, new_size[1] // 2)
            original_width, original_height = new_size
        
        # Check for specific sizes
        if ((1800 <= original_width <= 2200 and 2400 <= original_height <= 2800) or
            (2800 <= original_width <= 3200 and 3700 <= original_height <= 4100)):
            
            crop_ratio = 0.75 if original_width >= 2800 else 0.85
            
            crop_width = int(original_width * crop_ratio)
            crop_height = int(original_height * crop_ratio)
            
            left = image_center[0] - crop_width // 2
            top = image_center[1] - crop_height // 2
            
            cropped = image.crop((left, top, left + crop_width, top + crop_height))
            return cropped.resize((target_width, target_height), Image.Resampling.LANCZOS)
        else:
            # Simple resize
            width_ratio = target_width / original_width
            height_ratio = target_height / original_height
            scale_ratio = min(width_ratio, height_ratio)
            
            new_size = (int(original_width * scale_ratio), int(original_height * scale_ratio))
            resized = image.resize(new_size, Image.Resampling.LANCZOS)
            
            # Center on white background
            thumbnail = Image.new('RGB', (target_width, target_height), (255, 255, 255))
            left = (target_width - new_size[0]) // 2
            top = (target_height - new_size[1]) // 2
            thumbnail.paste(resized, (left, top))
            
            return thumbnail

def image_to_base64(image):
    """Convert to base64 without padding"""
    buffered = BytesIO()
    
    if image.mode == 'RGBA':
        background = Image.new('RGB', image.size, (255, 255, 255))
        background.paste(image, mask=image.split()[3])
        image = background
    
    image.save(buffered, format='PNG', optimize=False, quality=95)
    buffered.seek(0)
    
    return base64.b64encode(buffered.getvalue()).decode().rstrip('=')

def handler(event):
    """Optimized thumbnail handler - LIGHT GRAY SHADOW VERSION"""
    try:
        logger.info(f"=== Thumbnail {VERSION} Started ===")
        
        # Get image index
        image_index = event.get('image_index', 1)
        if isinstance(event.get('input'), dict):
            image_index = event.get('input', {}).get('image_index', image_index)
        
        # Fixed light gray background
        background_color = '#F0F0F0'  # Light gray
        
        # Fast extraction
        filename = find_filename_fast(event)
        input_data = find_input_data_fast(event)
        
        if not input_data:
            raise ValueError("No input data found")
        
        # Get image
        image = None
        priority_keys = ['image', 'image_base64', 'enhanced_image', 'base64']
        
        for key in priority_keys:
            if key in input_data and input_data[key]:
                try:
                    image = base64_to_image_fast(input_data[key])
                    break
                except:
                    continue
        
        if not image:
            raise ValueError("Failed to load image")
        
        # STEP 1: BACKGROUND REMOVAL (PNG only)
        original_mode = image.mode
        has_transparency = image.mode == 'RGBA'
        needs_background_removal = False
        
        if filename and filename.lower().endswith('.png'):
            logger.info("üì∏ STEP 1: PNG detected - removing background")
            image = remove_background_with_replicate(image)
            has_transparency = image.mode == 'RGBA'
            needs_background_removal = True
        
        # Keep transparent version for later
        if has_transparency:
            original_transparent = image.copy()
        
        # Convert to RGB for processing
        if image.mode != 'RGB':
            if image.mode == 'RGBA':
                temp_bg = Image.new('RGB', image.size, (255, 255, 255))
                temp_bg.paste(image, mask=image.split()[3])
                image = temp_bg
            else:
                image = image.convert('RGB')
        
        # STEP 2: ENHANCEMENT
        logger.info("üé® STEP 2: Applying enhancements")
        
        # Fast white balance
        image = auto_white_balance_fast(image)
        
        # Stronger basic enhancement
        brightness = ImageEnhance.Brightness(image)
        image = brightness.enhance(1.15)  # Increased from 1.12
        
        contrast = ImageEnhance.Contrast(image)
        image = contrast.enhance(1.08)  # Increased from 1.05
        
        color = ImageEnhance.Color(image)
        image = color.enhance(1.01)
        
        # Detect pattern
        pattern_type = detect_pattern_type(filename)
        
        # Create thumbnail
        thumbnail = create_thumbnail_optimized(image, 1000, 1300)
        
        # Apply SwinIR AFTER resize
        swinir_applied = False
        if USE_REPLICATE:
            try:
                logger.info("Applying SwinIR enhancement")
                thumbnail = apply_swinir_thumbnail_after_resize(thumbnail)
                swinir_applied = True
            except:
                logger.warning("SwinIR failed, continuing without")
        
        # Enhanced cubic details
        thumbnail = enhance_cubic_details_thumbnail_simple(thumbnail)
        
        detected_type = {
            "ac_pattern": "Î¨¥ÎèÑÍ∏àÌôîÏù¥Ìä∏(0.17/0.20)",
            "other": "Í∏∞ÌÉÄÏÉâÏÉÅ(no_overlay)"
        }.get(pattern_type, "Í∏∞ÌÉÄÏÉâÏÉÅ")
        
        # Apply pattern enhancement (includes 2Ï∞® Ï≤òÎ¶¨)
        thumbnail = apply_pattern_enhancement_fast(thumbnail, pattern_type)
        
        # STEP 3: BACKGROUND COMPOSITE (if transparent)
        if has_transparency and 'original_transparent' in locals():
            logger.info(f"üñºÔ∏è STEP 3: Light gray background compositing: {background_color}")
            
            # Apply enhancements to transparent version
            enhanced_transparent = original_transparent.resize((1000, 1300), Image.Resampling.LANCZOS)
            
            if enhanced_transparent.mode == 'RGBA':
                # Split channels
                r, g, b, a = enhanced_transparent.split()
                rgb_image = Image.merge('RGB', (r, g, b))
                
                # Apply same enhancements
                rgb_image = auto_white_balance_fast(rgb_image)
                rgb_image = enhance_cubic_details_thumbnail_simple(rgb_image)
                brightness = ImageEnhance.Brightness(rgb_image)
                rgb_image = brightness.enhance(1.15)
                contrast = ImageEnhance.Contrast(rgb_image)
                rgb_image = contrast.enhance(1.08)
                sharpness = ImageEnhance.Sharpness(rgb_image)
                rgb_image = sharpness.enhance(1.9)
                
                # Pattern enhancement based on type
                if pattern_type == "ac_pattern":
                    # 17% white overlay
                    white_overlay = 0.17
                    img_array = np.array(rgb_image, dtype=np.float32)
                    img_array = img_array * (1 - white_overlay) + 255 * white_overlay
                    rgb_image = Image.fromarray(np.clip(img_array, 0, 255).astype(np.uint8))
                
                # Merge back
                r2, g2, b2 = rgb_image.split()
                enhanced_transparent = Image.merge('RGBA', (r2, g2, b2, a))
            
            # Natural composite with light gray background
            thumbnail = composite_with_light_gray_background(enhanced_transparent, background_color)
            
            # Final sharpness after compositing
            sharpness = ImageEnhance.Sharpness(thumbnail)
            thumbnail = sharpness.enhance(1.2)  # Reduced for natural look
        
        # Final adjustments
        sharpness = ImageEnhance.Sharpness(thumbnail)
        thumbnail = sharpness.enhance(1.8)  # Reduced from 1.9 for more natural
        
        brightness = ImageEnhance.Brightness(thumbnail)
        thumbnail = brightness.enhance(1.04)  # Reduced from 1.05
        
        # Convert to base64
        thumbnail_base64 = image_to_base64(thumbnail)
        
        # Generate filename
        output_filename = generate_thumbnail_filename(filename, image_index)
        
        return {
            "output": {
                "thumbnail": thumbnail_base64,
                "size": list(thumbnail.size),
                "detected_type": detected_type,
                "pattern_type": pattern_type,
                "is_wedding_ring": True,
                "filename": output_filename,
                "original_filename": filename,
                "image_index": image_index,
                "format": "base64_no_padding",
                "version": VERSION,
                "status": "success",
                "swinir_applied": swinir_applied,
                "swinir_timing": "AFTER resize",
                "png_support": True,
                "has_transparency": has_transparency,
                "background_composite": has_transparency,
                "background_removal": needs_background_removal,
                "background_color": background_color,
                "background_style": "Light gray gradient (#F0F0F0)",
                "shadow_color": "Light gray (230, 230, 230)",
                "shadow_opacity": "Ultra-light (3%/2%/1%)",
                "edge_processing": "Strong natural feathering",
                "composite_method": "Premultiplied alpha blending",
                "rembg_settings": "Aggressive (270/10/10)",
                "expected_input": "2000x2600",
                "output_size": "1000x1300",
                "cubic_enhancement": "Strong (140% unsharp)",
                "white_overlay": "17% for ac_ (1Ï∞®), 20% (2Ï∞®)",
                "brightness_increased": "15%",
                "contrast_increased": "8%",
                "sharpness_increased": "1.8-1.9 + extra passes",
                "spotlight_increased": "3-4%",
                "processing_order": "1.Background Removal ‚Üí 2.Enhancement ‚Üí 3.Light Gray Composite",
                "quality": "95"
            }
        }
        
    except Exception as e:
        logger.error(f"Error: {str(e)}")
        import traceback
        
        return {
            "output": {
                "error": str(e),
                "status": "failed",
                "version": VERSION,
                "traceback": traceback.format_exc()
            }
        }

# RunPod handler
runpod.serverless.start({"handler": handler})
