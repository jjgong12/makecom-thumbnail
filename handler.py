import runpod
import os
import base64
import numpy as np
from io import BytesIO
from PIL import Image, ImageEnhance, ImageFilter, ImageDraw, ImageFont
import requests
import logging
import re
import replicate
import string
import cv2

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

################################
# THUMBNAIL HANDLER - 1000x1300
# VERSION: New-Neo-V3-Shadow-Fix-Ultra-Enhanced-White5-FingerShot
################################

VERSION = "New-Neo-V3-Shadow-Fix-Ultra-Enhanced-White5-FingerShot"

# ===== GLOBAL INITIALIZATION =====
REPLICATE_API_TOKEN = os.environ.get('REPLICATE_API_TOKEN')
REPLICATE_CLIENT = None

if REPLICATE_API_TOKEN:
    try:
        REPLICATE_CLIENT = replicate.Client(api_token=REPLICATE_API_TOKEN)
        logger.info("‚úÖ Replicate client initialized")
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize Replicate: {e}")

# Global rembg session with U2Net
REMBG_SESSION = None

# Global font cache
KOREAN_FONT = None
FONT_VERIFIED = False

def init_rembg_session():
    """Initialize rembg session with U2Net for faster processing"""
    global REMBG_SESSION
    if REMBG_SESSION is None:
        try:
            from rembg import new_session
            # Use U2Net for faster processing
            REMBG_SESSION = new_session('u2net')
            logger.info("‚úÖ U2Net session initialized for faster processing")
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize rembg: {e}")
            REMBG_SESSION = None
    return REMBG_SESSION

# Initialize on module load
init_rembg_session()

def download_korean_font():
    """Download Korean font for text rendering - WITH CACHING"""
    global KOREAN_FONT, FONT_VERIFIED
    
    # Return cached font if already verified
    if KOREAN_FONT and FONT_VERIFIED:
        return KOREAN_FONT
    
    try:
        font_path = '/tmp/NanumGothic.ttf'
        
        # If font exists and not verified, verify it
        if os.path.exists(font_path) and not FONT_VERIFIED:
            try:
                # Test with actual Korean text
                test_font = ImageFont.truetype(font_path, 20, encoding='utf-8')
                img_test = Image.new('RGBA', (200, 100), (255, 255, 255, 0))
                draw_test = ImageDraw.Draw(img_test)
                # Test with various Korean characters
                test_text = "ÌÖåÏä§Ìä∏ ÌïúÍ∏Ä Ìè∞Ìä∏ ÌôïÏù∏"
                draw_test.text((10, 10), test_text, font=test_font, fill='black')
                logger.info("‚úÖ Korean font verified and cached")
                KOREAN_FONT = font_path
                FONT_VERIFIED = True
                return font_path
            except Exception as e:
                logger.error(f"Font verification failed: {e}")
                os.remove(font_path)
                FONT_VERIFIED = False
        
        # Download if not exists or verification failed
        if not os.path.exists(font_path):
            font_urls = [
                'https://github.com/naver/nanumfont/raw/master/fonts/NanumFontSetup_TTF_GOTHIC/NanumGothic.ttf',
                'https://cdn.jsdelivr.net/gh/naver/nanumfont@master/fonts/NanumFontSetup_TTF_GOTHIC/NanumGothic.ttf',
                'https://github.com/naver/nanumfont/raw/master/fonts/NanumFontSetup_TTF_GOTHIC/NanumGothicBold.ttf'
            ]
            
            for url in font_urls:
                try:
                    logger.info(f"Downloading font from: {url}")
                    response = requests.get(url, timeout=30)
                    if response.status_code == 200 and len(response.content) > 100000:
                        with open(font_path, 'wb') as f:
                            f.write(response.content)
                        
                        # Verify the font works with Korean
                        test_font = ImageFont.truetype(font_path, 20, encoding='utf-8')
                        img_test = Image.new('RGBA', (200, 100), (255, 255, 255, 0))
                        draw_test = ImageDraw.Draw(img_test)
                        draw_test.text((10, 10), "ÌïúÍ∏Ä ÌÖåÏä§Ìä∏", font=test_font, fill='black')
                        logger.info("‚úÖ Korean font downloaded and verified successfully")
                        KOREAN_FONT = font_path
                        FONT_VERIFIED = True
                        return font_path
                except Exception as e:
                    logger.error(f"Failed to download from {url}: {e}")
                    continue
        
        logger.error("‚ùå Failed to download Korean font from all sources")
        return None
    except Exception as e:
        logger.error(f"Font download error: {e}")
        return None

def get_font(size, korean_font_path=None):
    """Get font with proper encoding - ENHANCED"""
    if korean_font_path and os.path.exists(korean_font_path):
        try:
            # Always use UTF-8 encoding for Korean fonts
            font = ImageFont.truetype(korean_font_path, size, encoding='utf-8')
            return font
        except Exception as e:
            logger.error(f"Font loading error: {e}")
    
    # Fallback to default
    try:
        logger.warning("Using default font as fallback")
        return ImageFont.load_default()
    except:
        return None

def safe_draw_text(draw, position, text, font, fill):
    """Safely draw text with proper encoding - ENHANCED"""
    try:
        if text and font:
            # Ensure text is properly encoded as UTF-8
            if isinstance(text, bytes):
                text = text.decode('utf-8', errors='replace')
            else:
                # Ensure it's a string and normalize
                text = str(text)
            
            # Draw the text
            draw.text(position, text, font=font, fill=fill)
    except Exception as e:
        logger.error(f"Text drawing error: {e}, text: {repr(text)}")
        # Fallback to simple text
        try:
            draw.text(position, "[Text Error]", font=font, fill=fill)
        except:
            pass

def get_text_size(draw, text, font):
    """Get text size compatible with different PIL versions"""
    try:
        # Ensure text is string
        if isinstance(text, bytes):
            text = text.decode('utf-8', errors='replace')
        else:
            text = str(text)
            
        bbox = draw.textbbox((0, 0), text, font=font)
        return bbox[2] - bbox[0], bbox[3] - bbox[1]
    except AttributeError:
        return draw.textsize(text, font=font)

def auto_crop_transparent(image):
    """Auto-crop transparent borders from image with padding"""
    if image.mode != 'RGBA':
        image = image.convert('RGBA')
    
    data = np.array(image)
    alpha = data[:,:,3]
    
    non_transparent = np.where(alpha > 10)
    
    if len(non_transparent[0]) == 0:
        return image
    
    min_y = non_transparent[0].min()
    max_y = non_transparent[0].max()
    min_x = non_transparent[1].min()
    max_x = non_transparent[1].max()
    
    padding = 10
    min_y = max(0, min_y - padding)
    max_y = min(data.shape[0] - 1, max_y + padding)
    min_x = max(0, min_x - padding)
    max_x = min(data.shape[1] - 1, max_x + padding)
    
    cropped = image.crop((min_x, min_y, max_x + 1, max_y + 1))
    
    # Ensure RGBA mode after crop
    if cropped.mode != 'RGBA':
        cropped = cropped.convert('RGBA')
    
    return cropped

def apply_enhanced_metal_color(image, metal_color, strength=0.3, color_id=""):
    """Apply enhanced metal color effect - Yellow/Rose/White/Antique Gold only"""
    # CRITICAL: Ensure RGBA mode
    if image.mode != 'RGBA':
        image = image.convert('RGBA')
    
    r, g, b, a = image.split()
    
    r_array = np.array(r, dtype=np.float32)
    g_array = np.array(g, dtype=np.float32)
    b_array = np.array(b, dtype=np.float32)
    a_array = np.array(a)
    
    mask = a_array > 0
    
    if mask.any():
        luminance = (0.299 * r_array + 0.587 * g_array + 0.114 * b_array) / 255.0
        
        metal_r, metal_g, metal_b = [c/255.0 for c in metal_color]
        
        if color_id == "white":
            brightness_boost = 1.05
            r_array[mask] = np.clip(r_array[mask] * brightness_boost, 0, 255)
            g_array[mask] = np.clip(g_array[mask] * brightness_boost, 0, 255)
            b_array[mask] = np.clip(b_array[mask] * brightness_boost, 0, 255)
        
        elif color_id == "rose":
            highlight_mask = luminance > 0.85
            shadow_mask = luminance < 0.15
            midtone_mask = ~highlight_mask & ~shadow_mask & mask
            
            if midtone_mask.any():
                blend_factor = 0.5
                r_array[midtone_mask] = r_array[midtone_mask] * (1 - blend_factor) + (255 * luminance[midtone_mask]) * blend_factor
                g_array[midtone_mask] = g_array[midtone_mask] * (1 - blend_factor) + (160 * luminance[midtone_mask]) * blend_factor
                b_array[midtone_mask] = b_array[midtone_mask] * (1 - blend_factor) + (120 * luminance[midtone_mask]) * blend_factor
            
            if highlight_mask.any():
                r_array[highlight_mask] = np.clip(r_array[highlight_mask] * 0.5 + 255 * 0.5, 0, 255)
                g_array[highlight_mask] = np.clip(g_array[highlight_mask] * 0.5 + 160 * 0.5, 0, 255)
                b_array[highlight_mask] = np.clip(b_array[highlight_mask] * 0.5 + 120 * 0.5, 0, 255)
            
            if shadow_mask.any():
                r_array[shadow_mask] = r_array[shadow_mask] * 0.8 + 50 * 0.2
                g_array[shadow_mask] = g_array[shadow_mask] * 0.8 + 30 * 0.2
                b_array[shadow_mask] = b_array[shadow_mask] * 0.8 + 20 * 0.2
        
        else:
            highlight_mask = luminance > 0.85
            shadow_mask = luminance < 0.15
            midtone_mask = ~highlight_mask & ~shadow_mask & mask
            
            if midtone_mask.any():
                blend_factor = strength * 2.0
                r_array[midtone_mask] = r_array[midtone_mask] * (1 - blend_factor) + (metal_r * 255 * luminance[midtone_mask]) * blend_factor
                g_array[midtone_mask] = g_array[midtone_mask] * (1 - blend_factor) + (metal_g * 255 * luminance[midtone_mask]) * blend_factor
                b_array[midtone_mask] = b_array[midtone_mask] * (1 - blend_factor) + (metal_b * 255 * luminance[midtone_mask]) * blend_factor
            
            if highlight_mask.any():
                tint_factor = strength * 0.5
                r_array[highlight_mask] = r_array[highlight_mask] * (1 - tint_factor) + (metal_r * 255) * tint_factor
                g_array[highlight_mask] = g_array[highlight_mask] * (1 - tint_factor) + (metal_g * 255) * tint_factor
                b_array[highlight_mask] = b_array[highlight_mask] * (1 - tint_factor) + (metal_b * 255) * tint_factor
            
            if shadow_mask.any():
                shadow_tint = strength * 0.2
                r_array[shadow_mask] = r_array[shadow_mask] * (1 - shadow_tint) + (metal_r * r_array[shadow_mask]) * shadow_tint
                g_array[shadow_mask] = g_array[shadow_mask] * (1 - shadow_tint) + (metal_g * g_array[shadow_mask]) * shadow_tint
                b_array[shadow_mask] = b_array[shadow_mask] * (1 - shadow_tint) + (metal_b * b_array[shadow_mask]) * shadow_tint
    
    r_array = np.clip(r_array, 0, 255)
    g_array = np.clip(g_array, 0, 255)
    b_array = np.clip(b_array, 0, 255)
    
    r_new = Image.fromarray(r_array.astype(np.uint8))
    g_new = Image.fromarray(g_array.astype(np.uint8))
    b_new = Image.fromarray(b_array.astype(np.uint8))
    
    # CRITICAL: Preserve alpha channel
    result = Image.merge('RGBA', (r_new, g_new, b_new, a))
    
    # Verify RGBA mode
    if result.mode != 'RGBA':
        logger.error("‚ùå WARNING: Metal color result is not RGBA!")
        result = result.convert('RGBA')
    
    return result

def create_color_section(ring_image, width=1200):
    """Create COLOR section with 4 metal variations - Yellow/Rose/White/Antique Gold only"""
    logger.info("Creating COLOR section with transparent PNGs")
    
    height = 850
    
    # Create section with WHITE background for display
    section_img = Image.new('RGB', (width, height), '#FFFFFF')
    draw = ImageDraw.Draw(section_img)
    
    korean_font_path = download_korean_font()
    title_font = get_font(56, korean_font_path)
    label_font = get_font(24, korean_font_path)
    
    # Title
    title = "COLOR"
    title_width, _ = get_text_size(draw, title, title_font)
    safe_draw_text(draw, (width//2 - title_width//2, 60), title, title_font, (40, 40, 40))
    
    # Remove background from ring image with ULTRA PRECISE V3 removal
    ring_no_bg = None
    if ring_image:
        try:
            logger.info("Removing background from ring image with ULTRA PRECISE V3 method")
            ring_no_bg = u2net_ultra_precise_removal_v3_shadow_fix_ultra_enhanced(ring_image)
            if ring_no_bg.mode != 'RGBA':
                ring_no_bg = ring_no_bg.convert('RGBA')
            ring_no_bg = auto_crop_transparent(ring_no_bg)
            logger.info("Background removed successfully with ultra precision V3")
        except Exception as e:
            logger.error(f"Failed to remove background: {e}")
            ring_no_bg = ring_image.convert('RGBA') if ring_image else None
    
    # Color definitions - ONLY 4 Gold types: Yellow/Rose/White/Antique
    colors = [
        ("yellow", "YELLOW GOLD", (255, 200, 50), 0.3),
        ("rose", "ROSE GOLD", (255, 160, 120), 0.35),
        ("white", "WHITE GOLD", (255, 255, 255), 0.0),
        ("antique", "ANTIQUE GOLD", (245, 235, 225), 0.1)
    ]
    
    # Grid layout
    grid_size = 260
    padding = 60
    start_x = (width - (grid_size * 2 + padding)) // 2
    start_y = 160
    
    for i, (color_id, label, color_rgb, strength) in enumerate(colors):
        row = i // 2
        col = i % 2
        
        x = start_x + col * (grid_size + padding)
        y = start_y + row * (grid_size + 100)
        
        # Create container with light background for visibility
        container = Image.new('RGBA', (grid_size, grid_size), (252, 252, 252, 255))
        container_draw = ImageDraw.Draw(container)
        
        # Border
        container_draw.rectangle([0, 0, grid_size-1, grid_size-1], 
                                fill=None, outline=(240, 240, 240), width=1)
        
        if ring_no_bg:
            try:
                # Copy ring and apply color
                ring_copy = ring_no_bg.copy()
                max_size = int(grid_size * 0.7)
                ring_copy.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                
                # Apply color - PRESERVING TRANSPARENCY
                ring_tinted = apply_enhanced_metal_color(ring_copy, color_rgb, strength, color_id)
                
                # Center placement - preserving transparency
                paste_x = (grid_size - ring_tinted.width) // 2
                paste_y = (grid_size - ring_tinted.height) // 2
                
                # Paste with alpha channel
                container.paste(ring_tinted, (paste_x, paste_y), ring_tinted)
                
                logger.info(f"Applied {color_id} color with transparency preserved")
                
            except Exception as e:
                logger.error(f"Error applying color {color_id}: {e}")
        
        # Convert container to RGB for final section image
        container_rgb = Image.new('RGB', container.size, (252, 252, 252))
        container_rgb.paste(container, mask=container.split()[3] if container.mode == 'RGBA' else None)
        
        # Paste container to section image
        section_img.paste(container_rgb, (x, y))
        
        # Add label
        label_width, _ = get_text_size(draw, label, label_font)
        safe_draw_text(draw, (x + grid_size//2 - label_width//2, y + grid_size + 20), 
                     label, label_font, (80, 80, 80))
    
    logger.info(f"COLOR section created: {width}x{height}")
    return section_img

def u2net_ultra_precise_removal_v3_shadow_fix_ultra_enhanced(image: Image.Image) -> Image.Image:
    """ULTRA PRECISE V3 ENHANCED - Same as Enhancement Handler for consistency"""
    try:
        from rembg import remove
        
        global REMBG_SESSION
        if REMBG_SESSION is None:
            REMBG_SESSION = init_rembg_session()
            if REMBG_SESSION is None:
                return image
        
        logger.info("üî∑ U2Net ULTRA PRECISE V3 ENHANCED - Maximum Shadow Removal")
        
        # CRITICAL: Ensure RGBA mode before processing
        if image.mode != 'RGBA':
            image = image.convert('RGBA')
        
        # Enhanced pre-processing for jewelry
        contrast = ImageEnhance.Contrast(image)
        image_enhanced = contrast.enhance(1.4)  # Even higher contrast
        
        # Save image to buffer
        buffered = BytesIO()
        image_enhanced.save(buffered, format="PNG", compress_level=3, optimize=True)
        buffered.seek(0)
        img_data = buffered.getvalue()
        
        # Apply U2Net removal with ULTRA settings
        output = remove(
            img_data,
            session=REMBG_SESSION,
            alpha_matting=True,
            alpha_matting_foreground_threshold=340,  # Even higher for maximum precision
            alpha_matting_background_threshold=0,
            alpha_matting_erode_size=0,  # No erosion for maximum detail
            only_mask=False,
            post_process_mask=True
        )
        
        result_image = Image.open(BytesIO(output))
        
        # CRITICAL: Ensure RGBA mode
        if result_image.mode != 'RGBA':
            result_image = result_image.convert('RGBA')
        
        # ULTRA edge refinement
        r, g, b, a = result_image.split()
        alpha_array = np.array(a, dtype=np.uint8)
        rgb_array = np.array(result_image.convert('RGB'), dtype=np.uint8)
        
        # Convert to float for processing
        alpha_float = alpha_array.astype(np.float32) / 255.0
        
        # STAGE 1: AGGRESSIVE shadow detection and removal
        logger.info("üîç AGGRESSIVE multi-level shadow detection...")
        
        gray = cv2.cvtColor(rgb_array, cv2.COLOR_RGB2GRAY)
        
        # Convert to multiple color spaces for comprehensive analysis
        hsv = cv2.cvtColor(rgb_array, cv2.COLOR_RGB2HSV)
        h_channel, s_channel, v_channel = cv2.split(hsv)
        
        lab = cv2.cvtColor(rgb_array, cv2.COLOR_RGB2LAB)
        l_channel, a_channel, b_channel = cv2.split(lab)
        
        # Multi-level shadow detection
        # Level 1: Any semi-transparent areas that might be shadows
        potential_shadows = (alpha_float > 0.01) & (alpha_float < 0.5)
        
        # Level 2: Low saturation gray areas
        gray_shadows = (s_channel < 30) & (v_channel < 200) & (alpha_float < 0.7)
        
        # Level 3: Edge-based shadow detection
        edges = cv2.Canny(gray, 30, 100)
        edge_dilated = cv2.dilate(edges, np.ones((7,7)), iterations=2)
        edge_shadows = (alpha_float < 0.8) & (~edge_dilated.astype(bool))
        
        # Level 4: LAB-based shadow detection
        lab_shadows = (l_channel < 180) & (np.abs(a_channel - 128) < 20) & (np.abs(b_channel - 128) < 20)
        
        # Combine all shadow detections
        all_shadows = potential_shadows | gray_shadows | edge_shadows | (lab_shadows & (alpha_float < 0.9))
        
        # AGGRESSIVE shadow removal
        if np.any(all_shadows):
            logger.info("üî• Removing detected shadows aggressively...")
            alpha_float[all_shadows] = 0
        
        # STAGE 2: Ultra-precise edge detection with 6 methods
        logger.info("üîç Ultra-precise 6-method edge detection...")
        
        # Method 1-2: Sobel with multiple kernel sizes
        sobel_3 = cv2.Sobel(gray, cv2.CV_64F, 1, 1, ksize=3)
        sobel_5 = cv2.Sobel(gray, cv2.CV_64F, 1, 1, ksize=5)
        sobel_7 = cv2.Sobel(gray, cv2.CV_64F, 1, 1, ksize=7)
        sobel_combined = np.maximum(np.maximum(np.abs(sobel_3), np.abs(sobel_5)), np.abs(sobel_7))
        sobel_edges = (sobel_combined / sobel_combined.max() * 255).astype(np.uint8) > 30
        
        # Method 3: Scharr for fine details
        scharrx = cv2.Scharr(gray, cv2.CV_64F, 1, 0)
        scharry = cv2.Scharr(gray, cv2.CV_64F, 0, 1)
        scharr_magnitude = np.sqrt(scharrx**2 + scharry**2)
        scharr_edges = (scharr_magnitude / scharr_magnitude.max() * 255).astype(np.uint8) > 30
        
        # Method 4: Laplacian for jewelry details
        laplacian = cv2.Laplacian(gray, cv2.CV_64F, ksize=3)
        laplacian_edges = np.abs(laplacian) > 25
        
        # Method 5-6: Multi-threshold Canny
        canny_low = cv2.Canny(gray, 20, 60)
        canny_mid = cv2.Canny(gray, 40, 120)
        canny_high = cv2.Canny(gray, 60, 180)
        
        # Combine all edge detections
        all_edges = sobel_edges | scharr_edges | laplacian_edges | (canny_low > 0) | (canny_mid > 0) | (canny_high > 0)
        
        # STAGE 3: Main object isolation with better component analysis
        logger.info("üîç Intelligent jewelry object isolation...")
        
        # Binary mask for main object
        alpha_binary = (alpha_float > 0.6).astype(np.uint8)
        
        # Clean up with morphology
        kernel_jewelry = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        alpha_binary = cv2.morphologyEx(alpha_binary, cv2.MORPH_CLOSE, kernel_jewelry)
        alpha_binary = cv2.morphologyEx(alpha_binary, cv2.MORPH_OPEN, np.ones((3,3)))
        
        num_labels, labels = cv2.connectedComponents(alpha_binary)
        
        if num_labels > 1:
            # Find all significant components
            sizes = [(i, np.sum(labels == i)) for i in range(1, num_labels)]
            sizes.sort(key=lambda x: x[1], reverse=True)
            
            # Keep only significant components
            main_mask = np.zeros_like(alpha_binary, dtype=bool)
            if sizes:
                main_size = sizes[0][1]
                min_component_size = max(100, main_size * 0.02)  # At least 2% of main object
                
                for label_id, size in sizes:
                    if size > min_component_size:
                        main_mask |= (labels == label_id)
            
            # Apply main mask
            alpha_float[~main_mask] = 0
        
        # STAGE 4: Remove any remaining gray artifacts
        logger.info("üîç Removing gray artifacts and edge noise...")
        
        # Find areas that look like shadows or artifacts
        gray_artifacts = (s_channel < 25) & (v_channel > 50) & (v_channel < 200) & (alpha_float > 0) & (alpha_float < 0.9)
        
        if np.any(gray_artifacts):
            alpha_float[gray_artifacts] = 0
        
        # STAGE 5: Sharp edge refinement
        logger.info("üîç Sharp edge refinement...")
        
        # Create sharp edges
        alpha_sharp = np.where(alpha_float > 0.7, 1.0, 0.0)
        
        # Minimal smoothing for anti-aliasing
        alpha_smooth = cv2.GaussianBlur(alpha_sharp, (3, 3), 0.5)
        
        # Ultra-sharp sigmoid
        k = 150  # Very high steepness
        threshold = 0.5
        alpha_sigmoid = 1 / (1 + np.exp(-k * (alpha_smooth - threshold)))
        
        # STAGE 6: Final cleanup
        logger.info("üîç Final cleanup...")
        
        # Remove any remaining small components
        alpha_binary_final = (alpha_sigmoid > 0.5).astype(np.uint8)
        num_labels_final, labels_final = cv2.connectedComponents(alpha_binary_final)
        
        if num_labels_final > 2:
            sizes_final = [(i, np.sum(labels_final == i)) for i in range(1, num_labels_final)]
            if sizes_final:
                sizes_final.sort(key=lambda x: x[1], reverse=True)
                # Keep only the largest component(s)
                min_size = max(100, alpha_array.size * 0.0001)
                
                valid_mask = np.zeros_like(alpha_binary_final, dtype=bool)
                for label_id, size in sizes_final:
                    if size > min_size:
                        valid_mask |= (labels_final == label_id)
                
                alpha_sigmoid[~valid_mask] = 0
        
        # Convert back to uint8
        alpha_array = np.clip(alpha_sigmoid * 255, 0, 255).astype(np.uint8)
        
        logger.info("‚úÖ ULTRA PRECISE V3 ENHANCED complete")
        
        a_new = Image.fromarray(alpha_array)
        result = Image.merge('RGBA', (r, g, b, a_new))
        
        # Verify RGBA mode
        if result.mode != 'RGBA':
            logger.error("‚ùå WARNING: Result is not RGBA!")
            result = result.convert('RGBA')
        
        return result
        
    except Exception as e:
        logger.error(f"U2Net removal failed: {e}")
        # Ensure RGBA mode even on failure
        if image.mode != 'RGBA':
            return image.convert('RGBA')
        return image

def ensure_ring_holes_transparent_ultra_v3_enhanced(image: Image.Image) -> Image.Image:
    """ULTRA PRECISE V3 ENHANCED - Same as Enhancement Handler for consistency"""
    # CRITICAL: Preserve RGBA mode
    if image.mode != 'RGBA':
        image = image.convert('RGBA')
    
    logger.info("üîç ULTRA PRECISE V3 ENHANCED Ring Hole Detection")
    
    r, g, b, a = image.split()
    alpha_array = np.array(a, dtype=np.uint8)
    rgb_array = np.array(image.convert('RGB'), dtype=np.uint8)
    
    h, w = alpha_array.shape
    
    # Convert to multiple color spaces
    hsv = cv2.cvtColor(rgb_array, cv2.COLOR_RGB2HSV)
    h_channel, s_channel, v_channel = cv2.split(hsv)
    
    lab = cv2.cvtColor(rgb_array, cv2.COLOR_RGB2LAB)
    l_channel, a_channel, b_channel = cv2.split(lab)
    
    gray = cv2.cvtColor(rgb_array, cv2.COLOR_RGB2GRAY)
    
    # STAGE 1: Comprehensive hole detection
    # Multiple criteria for hole detection
    very_bright_v = v_channel > 250
    very_bright_l = l_channel > 245
    very_bright_gray = gray > 245
    
    # Very low saturation
    very_low_saturation = s_channel < 15
    
    # Low color variance in LAB
    low_color_variance = (np.abs(a_channel - 128) < 15) & (np.abs(b_channel - 128) < 15)
    
    # Alpha-based detection
    alpha_holes = alpha_array < 30
    
    # Combine all criteria with more aggressive thresholds
    potential_holes = ((very_bright_v | very_bright_l | very_bright_gray) & 
                      (very_low_saturation | low_color_variance)) | alpha_holes
    
    # STAGE 2: Narrow region detection
    logger.info("üîç Detecting narrow regions and enclosed areas...")
    
    if np.any(alpha_array > 128):
        # Distance transform from object
        object_mask = (alpha_array > 128).astype(np.uint8)
        dist_transform = cv2.distanceTransform(object_mask, cv2.DIST_L2, 5)
        
        # Find narrow regions
        narrow_regions = (dist_transform > 1) & (dist_transform < 25)
        
        # Bright areas in narrow regions are likely holes
        narrow_bright = narrow_regions & ((gray > 240) | (v_channel > 245))
        potential_holes |= narrow_bright
        
        # Find enclosed regions
        inverted = cv2.bitwise_not(object_mask)
        num_inv_labels, inv_labels = cv2.connectedComponents(inverted)
        
        # Check each potential enclosed region
        for label in range(1, num_inv_labels):
            component = (inv_labels == label)
            if np.any(component):
                # Check if completely enclosed (doesn't touch border)
                dilated = cv2.dilate(component.astype(np.uint8), np.ones((5,5)), iterations=1)
                touches_border = np.any(dilated[0,:]) or np.any(dilated[-1,:]) or \
                               np.any(dilated[:,0]) or np.any(dilated[:,-1])
                
                if not touches_border:
                    # This is an enclosed region
                    component_pixels = rgb_array[component]
                    if len(component_pixels) > 0:
                        brightness = np.mean(component_pixels)
                        if brightness > 235:
                            potential_holes[component] = True
                            logger.info(f"Found enclosed bright region with brightness {brightness:.1f}")
    
    # Clean up noise
    kernel_clean = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    potential_holes = cv2.morphologyEx(potential_holes.astype(np.uint8), cv2.MORPH_OPEN, kernel_clean)
    potential_holes = cv2.morphologyEx(potential_holes, cv2.MORPH_CLOSE, kernel_clean)
    
    # Find connected components
    num_labels, labels = cv2.connectedComponents(potential_holes)
    
    holes_mask = np.zeros_like(alpha_array, dtype=np.float32)
    
    # STAGE 3: Validate each hole candidate with enhanced criteria
    for label in range(1, num_labels):
        component = (labels == label)
        component_size = np.sum(component)
        
        # Size constraints
        min_size = max(20, h * w * 0.00002)
        max_size = h * w * 0.25
        
        if min_size < component_size < max_size:
            coords = np.where(component)
            if len(coords[0]) == 0:
                continue
            
            # Analyze component in all color spaces
            component_pixels_rgb = rgb_array[component]
            component_pixels_hsv = np.column_stack((h_channel[component], 
                                                   s_channel[component], 
                                                   v_channel[component]))
            component_pixels_lab = np.column_stack((l_channel[component], 
                                                   a_channel[component], 
                                                   b_channel[component]))
            
            if len(component_pixels_rgb) > 0:
                # Multi-space analysis
                brightness_rgb = np.mean(component_pixels_rgb)
                brightness_v = np.mean(component_pixels_hsv[:, 2])
                brightness_l = np.mean(component_pixels_lab[:, 0])
                
                saturation_mean = np.mean(component_pixels_hsv[:, 1])
                
                # Color uniformity
                rgb_std = np.std(component_pixels_rgb, axis=0)
                max_rgb_std = np.max(rgb_std)
                
                lab_std = np.std(component_pixels_lab, axis=0)
                max_lab_std = np.max(lab_std)
                
                # Shape analysis
                component_uint8 = component.astype(np.uint8) * 255
                contours, _ = cv2.findContours(component_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                shape_score = 0
                is_enclosed = False
                
                if contours:
                    contour = contours[0]
                    area = cv2.contourArea(contour)
                    perimeter = cv2.arcLength(contour, True)
                    
                    if perimeter > 0 and area > 0:
                        # Circularity
                        circularity = (4 * np.pi * area) / (perimeter * perimeter)
                        
                        # Convexity
                        hull = cv2.convexHull(contour)
                        hull_area = cv2.contourArea(hull)
                        convexity = area / hull_area if hull_area > 0 else 0
                        
                        # Solidity (how "filled" the shape is)
                        solidity = area / hull_area if hull_area > 0 else 0
                        
                        shape_score = (circularity * 0.4 + convexity * 0.3 + solidity * 0.3)
                        
                        # Check if enclosed
                        x, y, w, h = cv2.boundingRect(contour)
                        roi = object_mask[y:y+h, x:x+w] if 'object_mask' in locals() else None
                        if roi is not None and roi.shape[0] > 0 and roi.shape[1] > 0:
                            # Check if the hole is surrounded by object
                            border_sum = np.sum(roi[0,:]) + np.sum(roi[-1,:]) + \
                                       np.sum(roi[:,0]) + np.sum(roi[:,-1])
                            if border_sum > (2 * (w + h) - 4) * 0.8:
                                is_enclosed = True
                
                # Enhanced confidence calculation
                confidence = 0.0
                
                # Brightness criteria (very important)
                if brightness_rgb > 245 and brightness_v > 250 and brightness_l > 245:
                    confidence += 0.4
                elif brightness_rgb > 235 and brightness_v > 240 and brightness_l > 235:
                    confidence += 0.3
                elif brightness_rgb > 225:
                    confidence += 0.2
                
                # Saturation criteria
                if saturation_mean < 10:
                    confidence += 0.25
                elif saturation_mean < 20:
                    confidence += 0.15
                
                # Color uniformity
                if max_rgb_std < 10 and max_lab_std < 10:
                    confidence += 0.2
                elif max_rgb_std < 20 and max_lab_std < 15:
                    confidence += 0.1
                
                # Shape criteria
                if shape_score > 0.6:
                    confidence += 0.15
                elif shape_score > 0.4:
                    confidence += 0.1
                
                # Bonus for enclosed regions
                if is_enclosed:
                    confidence += 0.2
                
                # Apply hole mask based on confidence
                if confidence > 0.5:
                    holes_mask[component] = 255
                    logger.info(f"Hole detected: brightness RGB/V/L={brightness_rgb:.1f}/{brightness_v:.1f}/{brightness_l:.1f}, "
                              f"saturation={saturation_mean:.1f}, uniformity={max_rgb_std:.1f}, "
                              f"shape={shape_score:.2f}, enclosed={is_enclosed}, confidence={confidence:.2f}")
    
    # STAGE 4: Apply holes with smooth transitions
    if np.any(holes_mask > 0):
        # Smooth the hole masks
        holes_mask_smooth = cv2.GaussianBlur(holes_mask, (5, 5), 1)
        
        # Create transition zones
        kernel_dilate = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        holes_dilated = cv2.dilate(holes_mask, kernel_dilate, iterations=1)
        transition_zone = (holes_dilated > 0) & (holes_mask < 255)
        
        alpha_float = alpha_array.astype(np.float32)
        
        # Apply holes
        alpha_float[holes_mask_smooth > 200] = 0
        
        # Smooth transitions
        if np.any(transition_zone):
            # Distance-based transition
            dist_from_hole = cv2.distanceTransform((holes_mask == 0).astype(np.uint8), cv2.DIST_L2, 3)
            transition_alpha = np.clip(dist_from_hole / 5, 0, 1)
            alpha_float[transition_zone] *= transition_alpha[transition_zone]
        
        alpha_array = np.clip(alpha_float, 0, 255).astype(np.uint8)
        
        logger.info("‚úÖ Ring holes applied with enhanced detection")
    
    a_new = Image.fromarray(alpha_array)
    result = Image.merge('RGBA', (r, g, b, a_new))
    
    # Verify RGBA mode
    if result.mode != 'RGBA':
        logger.error("‚ùå WARNING: Result is not RGBA!")
        result = result.convert('RGBA')
    
    return result

def process_color_section(job):
    """Process COLOR section special mode"""
    logger.info("Processing COLOR section special mode with ULTRA PRECISE V3 removal")
    
    try:
        # Find image data - FIXED
        image_data_str = find_input_data_fast(job)
        
        if not image_data_str:
            return {
                "output": {
                    "error": "No image data found for COLOR section",
                    "status": "error",
                    "version": VERSION
                }
            }
        
        # Decode and open image
        image_bytes = decode_base64_fast(image_data_str)
        ring_image = Image.open(BytesIO(image_bytes))
        
        # Create COLOR section
        color_section = create_color_section(ring_image, width=1200)
        
        # Convert to base64
        buffered = BytesIO()
        color_section.save(buffered, format="PNG", optimize=True, compress_level=3)
        buffered.seek(0)
        section_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
        # FIXED: Keep padding for Google Script compatibility
        
        logger.info("COLOR section created successfully")
        
        return {
            "output": {
                "thumbnail": section_base64,
                "size": list(color_section.size),
                "section_type": "color",
                "special_mode": "color_section",
                "filename": "ac_wedding_011.png",
                "file_number": "011",
                "version": VERSION,
                "status": "success",
                "format": "base64_with_padding",
                "colors_generated": ["YELLOW GOLD", "ROSE GOLD", "WHITE GOLD", "ANTIQUE GOLD"],
                "background_removal": "ULTRA_PRECISE_V3_ENHANCED",
                "transparency_info": "Each ring variant has transparent background",
                "base64_padding": "INCLUDED",
                "compression": "level_3"
            }
        }
        
    except Exception as e:
        logger.error(f"Error creating COLOR section: {str(e)}")
        import traceback
        
        return {
            "output": {
                "error": str(e),
                "status": "error",
                "version": VERSION,
                "traceback": traceback.format_exc()
            }
        }

def find_input_data_fast(data):
    """FIXED: Fast input data extraction - consistent string return"""
    # Handle string input
    if isinstance(data, str) and len(data) > 50:
        return data
    
    # Handle dictionary input
    if isinstance(data, dict):
        priority_keys = ['image', 'image_base64', 'enhanced_image', 'base64', 'img']
        
        # Check priority keys first
        for key in priority_keys:
            if key in data and isinstance(data[key], str) and len(data[key]) > 50:
                return data[key]
        
        # Check nested structures
        for key in ['input', 'data']:
            if key in data and isinstance(data[key], dict):
                result = find_input_data_fast(data[key])
                if result:
                    return result
            elif key in data and isinstance(data[key], str) and len(data[key]) > 50:
                return data[key]
        
        # Check numbered keys as fallback
        for i in range(10):
            if str(i) in data and isinstance(data[str(i)], str) and len(data[str(i)]) > 50:
                return data[str(i)]
    
    return None

def find_filename_fast(data):
    """Fast filename extraction"""
    if isinstance(data, dict):
        for key in ['filename', 'file_name', 'name']:
            if key in data and isinstance(data[key], str):
                return data[key]
        
        if 'input' in data and isinstance(data['input'], dict):
            for key in ['filename', 'file_name', 'name']:
                if key in data['input']:
                    return data['input'][key]
    
    return None

def generate_thumbnail_filename(original_filename, image_index):
    """Generate thumbnail filename with fixed numbers"""
    if not original_filename:
        return f"thumbnail_{image_index:03d}.png"
    
    # Fixed thumbnail numbers: 007, 009, 010
    thumbnail_numbers = {1: "007", 2: "009", 3: "010"}
    
    new_filename = original_filename
    pattern = r'(_\d{3})'
    if re.search(pattern, new_filename):
        new_filename = re.sub(pattern, f'_{thumbnail_numbers.get(image_index, "007")}', new_filename)
    else:
        name_parts = new_filename.split('.')
        name_parts[0] += f'_{thumbnail_numbers.get(image_index, "007")}'
        new_filename = '.'.join(name_parts)
    
    return new_filename

def decode_base64_fast(base64_str: str) -> bytes:
    """ENHANCED: Fast base64 decode with consistent padding handling"""
    try:
        if not base64_str or len(base64_str) < 50:
            raise ValueError("Invalid base64 string")
        
        # Remove data URL prefix if present
        if 'base64,' in base64_str:
            base64_str = base64_str.split('base64,')[-1]
        
        # Clean whitespace
        base64_str = ''.join(base64_str.split())
        
        # Keep only valid base64 characters
        valid_chars = set(string.ascii_letters + string.digits + '+/=')
        base64_str = ''.join(c for c in base64_str if c in valid_chars)
        
        # FIXED: Try with padding first (normal base64)
        try:
            decoded = base64.b64decode(base64_str, validate=True)
            return decoded
        except Exception:
            # If fails, try to add proper padding
            no_pad = base64_str.rstrip('=')
            padding_needed = (4 - len(no_pad) % 4) % 4
            padded = no_pad + ('=' * padding_needed)
            decoded = base64.b64decode(padded, validate=True)
            return decoded
            
    except Exception as e:
        logger.error(f"Base64 decode error: {str(e)}")
        raise ValueError(f"Invalid base64 data: {str(e)}")

def base64_to_image_fast(base64_string):
    """ENHANCED: Fast base64 to image conversion with consistent handling"""
    try:
        image_bytes = decode_base64_fast(base64_string)
        return Image.open(BytesIO(image_bytes))
    except Exception as e:
        logger.error(f"Base64 to image error: {str(e)}")
        raise ValueError(f"Invalid image data: {str(e)}")

def detect_pattern_type(filename: str) -> str:
    """Detect pattern type - Updated with AB pattern"""
    if not filename:
        return "other"
    
    filename_lower = filename.lower()
    
    if 'ac_' in filename_lower:
        return "ac_pattern"
    elif 'ab_' in filename_lower:
        return "ab_pattern"
    else:
        return "other"

def create_thumbnail_proportional(image, target_width=1000, target_height=1300):
    """Create thumbnail with proper proportional sizing - preserving transparency"""
    # CRITICAL: Ensure RGBA mode
    if image.mode != 'RGBA':
        logger.warning(f"‚ö†Ô∏è Converting {image.mode} to RGBA in thumbnail creation")
        image = image.convert('RGBA')
    
    original_width, original_height = image.size
    
    logger.info(f"Creating proportional thumbnail from {original_width}x{original_height} to {target_width}x{target_height}")
    
    # For 2000x2600 -> 1000x1300, it's exactly 50% resize
    if original_width == 2000 and original_height == 2600:
        logger.info("Direct 50% resize for standard input size")
        result = image.resize((target_width, target_height), Image.Resampling.LANCZOS)
    else:
        # For other sizes, maintain aspect ratio
        scale_x = target_width / original_width
        scale_y = target_height / original_height
        scale = min(scale_x, scale_y)
        
        new_width = int(original_width * scale)
        new_height = int(original_height * scale)
        
        # Resize first
        resized = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        # Center crop if needed - preserving transparency
        if new_width != target_width or new_height != target_height:
            # Create transparent background
            result = Image.new('RGBA', (target_width, target_height), (0, 0, 0, 0))
            
            # Center paste
            paste_x = (target_width - new_width) // 2
            paste_y = (target_height - new_height) // 2
            
            result.paste(resized, (paste_x, paste_y), resized)
        else:
            result = resized
    
    # Verify RGBA mode
    if result.mode != 'RGBA':
        logger.error("‚ùå WARNING: Thumbnail is not RGBA!")
        result = result.convert('RGBA')
    
    return result

def apply_swinir_thumbnail(image: Image.Image) -> Image.Image:
    """Apply SwinIR enhancement for thumbnails while preserving transparency"""
    if not REPLICATE_CLIENT:
        logger.warning("SwinIR skipped - no Replicate client")
        return image
    
    try:
        logger.info("üé® Applying SwinIR enhancement with transparency support")
        
        # CRITICAL: Ensure RGBA mode
        if image.mode != 'RGBA':
            logger.warning(f"‚ö†Ô∏è Converting {image.mode} to RGBA for SwinIR")
            image = image.convert('RGBA')
        
        # Separate alpha channel
        r, g, b, a = image.split()
        rgb_image = Image.merge('RGB', (r, g, b))
        
        buffered = BytesIO()
        rgb_image.save(buffered, format="PNG", optimize=True, compress_level=3)
        buffered.seek(0)
        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
        img_data_url = f"data:image/png;base64,{img_base64}"
        
        output = REPLICATE_CLIENT.run(
            "jingyunliang/swinir:660d922d33153019e8c263a3bba265de882e7f4f70396546b6c9c8f9d47a021a",
            input={
                "image": img_data_url,
                "task_type": "Real-World Image Super-Resolution",
                "scale": 1,
                "noise_level": 10,
                "jpeg_quality": 50
            }
        )
        
        if output:
            if isinstance(output, str):
                response = requests.get(output)
                enhanced_image = Image.open(BytesIO(response.content))
            else:
                enhanced_image = Image.open(BytesIO(base64.b64decode(output)))
            
            # Recombine with alpha
            r2, g2, b2 = enhanced_image.split()
            result = Image.merge('RGBA', (r2, g2, b2, a))
            
            logger.info("‚úÖ SwinIR enhancement successful with transparency")
            
            # Verify RGBA mode
            if result.mode != 'RGBA':
                logger.error("‚ùå WARNING: SwinIR result is not RGBA!")
                result = result.convert('RGBA')
            
            return result
            
    except Exception as e:
        logger.warning(f"SwinIR error: {str(e)}")
        
    return image

def auto_white_balance_fast(image: Image.Image) -> Image.Image:
    """Fast white balance - preserving transparency"""
    # CRITICAL: Ensure RGBA mode
    if image.mode != 'RGBA':
        logger.warning(f"‚ö†Ô∏è Converting {image.mode} to RGBA for white balance")
        image = image.convert('RGBA')
    
    r, g, b, a = image.split()
    rgb_img = Image.merge('RGB', (r, g, b))
    
    img_array = np.array(rgb_img, dtype=np.float32)
    
    sampled = img_array[::15, ::15]
    gray_mask = (
        (np.abs(sampled[:,:,0] - sampled[:,:,1]) < 15) & 
        (np.abs(sampled[:,:,1] - sampled[:,:,2]) < 15) &
        (sampled[:,:,0] > 180)
    )
    
    if np.sum(gray_mask) > 10:
        r_avg = np.mean(sampled[gray_mask, 0])
        g_avg = np.mean(sampled[gray_mask, 1])
        b_avg = np.mean(sampled[gray_mask, 2])
        
        gray_avg = (r_avg + g_avg + b_avg) / 3
        
        img_array[:,:,0] *= (gray_avg / r_avg) if r_avg > 0 else 1
        img_array[:,:,1] *= (gray_avg / g_avg) if g_avg > 0 else 1
        img_array[:,:,2] *= (gray_avg / b_avg) if b_avg > 0 else 1
    
    rgb_balanced = Image.fromarray(np.clip(img_array, 0, 255).astype(np.uint8))
    r2, g2, b2 = rgb_balanced.split()
    result = Image.merge('RGBA', (r2, g2, b2, a))
    
    # Verify RGBA mode
    if result.mode != 'RGBA':
        logger.error("‚ùå WARNING: White balance result is not RGBA!")
        result = result.convert('RGBA')
    
    return result

def apply_pattern_enhancement_transparent(image: Image.Image, pattern_type: str) -> Image.Image:
    """Apply pattern enhancement while TRULY preserving transparency - AC 20%, AB 16%, Other 5% - UPDATED"""
    # CRITICAL: Ensure RGBA mode
    if image.mode != 'RGBA':
        logger.warning(f"‚ö†Ô∏è Converting {image.mode} to RGBA in pattern enhancement")
        image = image.convert('RGBA')
    
    # CRITICAL: Process RGB channels separately to preserve alpha
    r, g, b, a = image.split()
    rgb_image = Image.merge('RGB', (r, g, b))
    
    # Convert to array for processing
    img_array = np.array(rgb_image, dtype=np.float32)
    
    # Apply enhancements based on pattern type - UPDATED WITH 5% FOR OTHER
    if pattern_type == "ac_pattern":
        logger.info("üîç AC Pattern - Applying 20% white overlay with brightness 1.03")
        # Apply 20% white overlay
        white_overlay = 0.20
        img_array = img_array * (1 - white_overlay) + 255 * white_overlay
        img_array = np.clip(img_array, 0, 255)
        
        # Convert back to image
        rgb_image = Image.fromarray(img_array.astype(np.uint8))
        
        # UPDATED: Brightness increased by 0.01
        brightness = ImageEnhance.Brightness(rgb_image)
        rgb_image = brightness.enhance(1.03)  # Changed from 1.02
        
        color = ImageEnhance.Color(rgb_image)
        rgb_image = color.enhance(0.98)
        
        logger.info("‚úÖ AC Pattern enhancement applied with 20% white overlay")
    
    elif pattern_type == "ab_pattern":
        logger.info("üîç AB Pattern - Applying 16% white overlay and cool tone with brightness 1.03")
        # Apply 16% white overlay
        white_overlay = 0.16
        img_array = img_array * (1 - white_overlay) + 255 * white_overlay
        
        # Cool tone adjustment
        img_array[:,:,0] *= 0.96  # Reduce red
        img_array[:,:,1] *= 0.98  # Reduce green
        img_array[:,:,2] *= 1.02  # Increase blue
        
        # Cool color grading
        cool_overlay = np.array([240, 248, 255], dtype=np.float32)
        img_array = img_array * 0.95 + cool_overlay * 0.05
        
        img_array = np.clip(img_array, 0, 255)
        rgb_image = Image.fromarray(img_array.astype(np.uint8))
        
        color = ImageEnhance.Color(rgb_image)
        rgb_image = color.enhance(0.88)
        
        # UPDATED: Brightness increased by 0.01
        brightness = ImageEnhance.Brightness(rgb_image)
        rgb_image = brightness.enhance(1.03)  # Changed from 1.02
        
        logger.info("‚úÖ AB Pattern enhancement applied with 16% white overlay")
        
    else:
        logger.info("üîç Other Pattern - Applying 5% white overlay with brightness 1.09")
        # NEW: Apply 5% white overlay for other patterns
        white_overlay = 0.05
        img_array = img_array * (1 - white_overlay) + 255 * white_overlay
        img_array = np.clip(img_array, 0, 255)
        
        # Convert back to image
        rgb_image = Image.fromarray(img_array.astype(np.uint8))
        
        # UPDATED: Brightness increased by 0.01
        brightness = ImageEnhance.Brightness(rgb_image)
        rgb_image = brightness.enhance(1.09)  # Changed from 1.08
        
        color = ImageEnhance.Color(rgb_image)
        rgb_image = color.enhance(0.99)
        
        # MATCHED WITH ENHANCEMENT: Use 1.5 for Other pattern
        sharpness = ImageEnhance.Sharpness(rgb_image)
        rgb_image = sharpness.enhance(1.5)
        
        logger.info("‚úÖ Other Pattern enhancement applied with 5% white overlay")
    
    # UPDATED: Apply common enhancements with contrast 1.1
    contrast = ImageEnhance.Contrast(rgb_image)
    rgb_image = contrast.enhance(1.1)  # Changed from 1.06
    
    # Apply sharpening - EXACTLY SAME AS ENHANCEMENT HANDLER
    sharpness = ImageEnhance.Sharpness(rgb_image)
    rgb_image = sharpness.enhance(1.8)
    
    # CRITICAL: Recombine with ORIGINAL alpha channel
    r2, g2, b2 = rgb_image.split()
    enhanced_image = Image.merge('RGBA', (r2, g2, b2, a))
    
    logger.info(f"‚úÖ Enhancement applied with contrast 1.1 and updated brightness. Mode: {enhanced_image.mode}")
    
    # Verify RGBA mode
    if enhanced_image.mode != 'RGBA':
        logger.error("‚ùå WARNING: Enhanced image is not RGBA!")
        enhanced_image = enhanced_image.convert('RGBA')
    
    return enhanced_image

def image_to_base64(image, keep_transparency=True):
    """Convert to base64 WITH padding - FIXED for Google Script compatibility"""
    buffered = BytesIO()
    
    # CRITICAL FIX: Force RGBA and save as PNG
    if image.mode != 'RGBA' and keep_transparency:
        logger.warning(f"‚ö†Ô∏è Converting {image.mode} to RGBA for transparency")
        image = image.convert('RGBA')
    
    if image.mode == 'RGBA':
        logger.info("üíé Saving RGBA image as PNG with compression level 3")
        image.save(buffered, format='PNG', compress_level=3, optimize=True)
    else:
        logger.info(f"Saving {image.mode} mode image as PNG")
        image.save(buffered, format='PNG', optimize=True, compress_level=3)
    
    buffered.seek(0)
    base64_str = base64.b64encode(buffered.getvalue()).decode('utf-8')
    # FIXED: Always return WITH padding for Google Script compatibility
    return base64_str

def create_ring_on_finger_shot(ring_image, job):
    """Create ring-on-finger shot for 005 files"""
    logger.info("üñêÔ∏è Creating ring-on-finger shot for 005 file")
    
    try:
        # Process ring - remove background
        logger.info("Removing background from ring")
        ring_no_bg = u2net_ultra_precise_removal_v3_shadow_fix_ultra_enhanced(ring_image)
        if ring_no_bg.mode != 'RGBA':
            ring_no_bg = ring_no_bg.convert('RGBA')
        ring_no_bg = auto_crop_transparent(ring_no_bg)
        
        # Apply ring hole detection
        ring_no_bg = ensure_ring_holes_transparent_ultra_v3_enhanced(ring_no_bg)
        
        # Create hand image (base template)
        # For now, create a simple placeholder - you would replace this with actual hand image
        hand_width, hand_height = 1000, 1300
        
        # Create white background with hand placeholder
        final_image = Image.new('RGB', (hand_width, hand_height), '#FFFFFF')
        
        # Define ring finger position (approximate coordinates)
        # These would be adjusted based on actual hand image
        ring_finger_x = hand_width // 2 - 50  # Center horizontally
        ring_finger_y = int(hand_height * 0.45)  # About 45% down from top
        ring_angle = -5  # Slight angle for natural look
        
        # Resize ring to appropriate size for finger
        ring_width = int(hand_width * 0.15)  # Ring width about 15% of hand width
        ring_ratio = ring_no_bg.height / ring_no_bg.width
        ring_height = int(ring_width * ring_ratio)
        
        ring_resized = ring_no_bg.resize((ring_width, ring_height), Image.Resampling.LANCZOS)
        
        # Rotate ring slightly for natural positioning
        ring_rotated = ring_resized.rotate(ring_angle, expand=True, fillcolor=(0,0,0,0))
        
        # Create shadow for realism
        shadow = Image.new('RGBA', ring_rotated.size, (0, 0, 0, 0))
        shadow_draw = ImageDraw.Draw(shadow)
        
        # Simple elliptical shadow
        shadow_offset_x = 5
        shadow_offset_y = 5
        shadow_blur = 3
        
        # Get ring alpha for shadow shape
        _, _, _, ring_alpha = ring_rotated.split()
        shadow_alpha = ring_alpha.point(lambda x: int(x * 0.3))  # 30% opacity shadow
        shadow = Image.merge('RGBA', (Image.new('L', ring_rotated.size, 0),
                                      Image.new('L', ring_rotated.size, 0),
                                      Image.new('L', ring_rotated.size, 0),
                                      shadow_alpha))
        
        # Blur shadow
        shadow = shadow.filter(ImageFilter.GaussianBlur(radius=shadow_blur))
        
        # Paste shadow first
        final_image.paste(shadow, 
                         (ring_finger_x + shadow_offset_x, ring_finger_y + shadow_offset_y),
                         shadow)
        
        # Paste ring
        final_image.paste(ring_rotated, (ring_finger_x, ring_finger_y), ring_rotated)
        
        # Add text overlay
        korean_font_path = download_korean_font()
        if korean_font_path:
            draw = ImageDraw.Draw(final_image)
            text_font = get_font(24, korean_font_path)
            text = "Ï∞©Ïö© Ïù¥ÎØ∏ÏßÄ"
            text_width, text_height = get_text_size(draw, text, text_font)
            text_x = (hand_width - text_width) // 2
            text_y = hand_height - 100
            safe_draw_text(draw, (text_x, text_y), text, text_font, (100, 100, 100))
        
        logger.info("‚úÖ Ring-on-finger shot created successfully")
        return final_image
        
    except Exception as e:
        logger.error(f"Failed to create ring-on-finger shot: {e}")
        # Return original image as fallback
        return ring_image

def handler(event):
    """Optimized thumbnail handler - New Neo V3 Shadow Fix Ultra Enhanced - WITH 5% WHITE OVERLAY FOR OTHER"""
    try:
        logger.info(f"=== Thumbnail {VERSION} Started ===")
        logger.info("üéØ NEW NEO V3: Shadow Fix Ultra Enhanced with 5% White Overlay for Other")
        logger.info("üíé TRANSPARENT OUTPUT: Preserving alpha channel throughout")
        logger.info("üî• AGGRESSIVE SHADOW REMOVAL: Multi-level + LAB color space")
        logger.info("üîß AC PATTERN: 20% white overlay, brightness 1.03, contrast 1.1")
        logger.info("üîß AB PATTERN: 16% white overlay, brightness 1.03, contrast 1.1")
        logger.info("‚ú® OTHER PATTERNS: 5% white overlay, brightness 1.09, contrast 1.1")
        logger.info("üé® COLORS: Yellow/Rose/White/Antique Gold only")
        logger.info("üîÑ PROCESSING ORDER: 1.Pattern Enhancement ‚Üí 2.Resize ‚Üí 3.SwinIR ‚Üí 4.Ring Holes")
        logger.info("üìå BASE64 PADDING: ALWAYS INCLUDED for Google Script compatibility")
        logger.info("üóúÔ∏è COMPRESSION: Level 3 (balanced speed/size)")
        logger.info("üÜï 6-METHOD EDGE DETECTION: Sobel(3,5,7) + Scharr + Laplacian + Canny")
        logger.info("üÜï MULTI-COLOR SPACE HOLE DETECTION: RGB + HSV + LAB")
        logger.info("üÜï ENCLOSED REGION DETECTION: For inner ring holes")
        logger.info("‚ö° CONTRAST: 1.1 (updated from 1.06)")
        logger.info("‚ö° BRIGHTNESS: All patterns +0.01 increase")
        logger.info("üîó MATCHING: Using same V3 Enhanced removal as Enhancement Handler")
        logger.info("üÜï OTHER PATTERN: Now with 5% white overlay")
        logger.info("üÜï 005 FILES: Ring-on-finger shot feature")
        
        # Check for special mode first
        if event.get('special_mode') == 'color_section':
            return process_color_section(event)
        
        # Normal thumbnail processing with MATCHED ORDER
        image_index = event.get('image_index', 1)
        if isinstance(event.get('input'), dict):
            image_index = event.get('input', {}).get('image_index', image_index)
        
        filename = find_filename_fast(event)
        image_data_str = find_input_data_fast(event)
        
        if not image_data_str:
            raise ValueError("No input data found")
        
        # Load image using fixed function
        image = base64_to_image_fast(image_data_str)
        
        # CRITICAL: Convert to RGBA immediately
        if image.mode != 'RGBA':
            logger.info(f"Converting {image.mode} to RGBA immediately")
            image = image.convert('RGBA')
        
        # Check if this is a 005 file
        is_005_file = False
        if filename and '005' in filename:
            is_005_file = True
            logger.info("üñêÔ∏è Detected 005 file - will create ring-on-finger shot")
        
        # STEP 1: ALWAYS apply background removal with V3 ENHANCED (matching Enhancement Handler)
        logger.info("üì∏ STEP 1: ALWAYS applying ULTRA PRECISE V3 ENHANCED background removal")
        image = u2net_ultra_precise_removal_v3_shadow_fix_ultra_enhanced(image)
        
        # Verify RGBA after removal
        if image.mode != 'RGBA':
            logger.error("‚ùå Image lost RGBA after background removal!")
            image = image.convert('RGBA')
        
        # If 005 file, create ring-on-finger shot
        if is_005_file:
            logger.info("üñêÔ∏è Creating ring-on-finger shot for 005 file")
            thumbnail = create_ring_on_finger_shot(image, event)
        else:
            # Normal thumbnail processing
            # STEP 2: Apply white balance
            logger.info("‚öñÔ∏è STEP 2: Applying white balance")
            image = auto_white_balance_fast(image)
            
            # STEP 3: PATTERN ENHANCEMENT FIRST (MATCHED ORDER)
            logger.info("üé® STEP 3: Applying pattern enhancement FIRST (matched with Enhancement Handler)")
            pattern_type = detect_pattern_type(filename)
            
            detected_type = {
                "ac_pattern": "Î¨¥ÎèÑÍ∏àÌôîÏù¥Ìä∏(0.20)",
                "ab_pattern": "Î¨¥ÎèÑÍ∏àÌôîÏù¥Ìä∏-Ïø®ÌÜ§(0.16)",
                "other": "Í∏∞ÌÉÄÏÉâÏÉÅ(0.05)"
            }.get(pattern_type, "Í∏∞ÌÉÄÏÉâÏÉÅ")
            
            # Apply pattern enhancement with UPDATED settings
            image = apply_pattern_enhancement_transparent(image, pattern_type)
            
            # STEP 4: RESIZE (MATCHED ORDER)
            logger.info("üìè STEP 4: Creating proportional thumbnail")
            thumbnail = create_thumbnail_proportional(image, 1000, 1300)
            
            # STEP 5: SWINIR ENHANCEMENT (MATCHED ORDER)
            logger.info("üöÄ STEP 5: Applying SwinIR enhancement")
            thumbnail = apply_swinir_thumbnail(thumbnail)
            
            # STEP 6: Ultra precise V3 ENHANCED ring hole detection (MATCHED ORDER)
            logger.info("üîç STEP 6: Applying ULTRA PRECISE V3 ENHANCED ring hole detection")
            thumbnail = ensure_ring_holes_transparent_ultra_v3_enhanced(thumbnail)
        
        # Final verification
        if thumbnail.mode != 'RGBA' and not is_005_file:
            logger.error("‚ùå CRITICAL: Final thumbnail is not RGBA! Converting...")
            thumbnail = thumbnail.convert('RGBA')
        
        # CRITICAL: NO BACKGROUND COMPOSITE - Keep transparency (unless 005 file)
        if not is_005_file:
            logger.info("üíé NO background composite - keeping pure transparency")
        else:
            logger.info("üñêÔ∏è Ring-on-finger shot created with white background")
        
        logger.info(f"‚úÖ Final thumbnail mode: {thumbnail.mode}")
        logger.info(f"‚úÖ Final thumbnail size: {thumbnail.size}")
        
        # Convert to base64 - WITH padding for Google Script
        thumbnail_base64 = image_to_base64(thumbnail, keep_transparency=(not is_005_file))
        
        # Verify transparency is preserved
        if not is_005_file:
            logger.info("‚úÖ Transparency preserved in final output")
        
        output_filename = generate_thumbnail_filename(filename, image_index)
        
        # Special handling for 005 files
        if is_005_file:
            output_filename = filename.replace('.png', '_finger_shot.png') if filename else 'finger_shot_005.png'
        
        return {
            "output": {
                "thumbnail": thumbnail_base64,
                "size": list(thumbnail.size),
                "detected_type": detected_type if not is_005_file else "finger_shot",
                "pattern_type": pattern_type if not is_005_file else "finger_shot",
                "is_wedding_ring": True,
                "is_finger_shot": is_005_file,
                "filename": output_filename,
                "original_filename": filename,
                "image_index": image_index,
                "format": "base64_with_padding",
                "version": VERSION,
                "status": "success",
                "swinir_applied": True,
                "swinir_timing": "AFTER pattern enhancement and resize",
                "png_support": True,
                "has_transparency": not is_005_file,
                "transparency_preserved": not is_005_file,
                "background_removed": True,
                "background_applied": is_005_file,
                "output_mode": "RGB" if is_005_file else "RGBA",
                "base64_padding": "INCLUDED",
                "compression": "level_3",
                "special_modes_available": ["color_section", "finger_shot_005"],
                "file_number_info": {
                    "005": "Ring-on-finger shot",
                    "007": "Thumbnail 1",
                    "009": "Thumbnail 2", 
                    "010": "Thumbnail 3",
                    "011": "COLOR section"
                },
                "contrast_brightness_update": {
                    "contrast": "1.1 (updated from 1.06)",
                    "brightness_ac_ab": "1.03 (increased from 1.02)",
                    "brightness_other": "1.09 (increased from 1.08)",
                    "white_overlay_ac": "20%",
                    "white_overlay_ab": "16%",
                    "white_overlay_other": "5% (NEW)",
                    "reason": "User requested 5% white overlay for other patterns"
                },
                "new_neo_v3_enhanced_features": [
                    "‚úÖ AGGRESSIVE SHADOW REMOVAL: Multi-level + LAB color space",
                    "‚úÖ 6-METHOD EDGE DETECTION: Sobel(3,5,7) + Scharr + Laplacian + Canny(3 levels)",
                    "‚úÖ ENHANCED OBJECT ISOLATION: Better component analysis",
                    "‚úÖ GRAY ARTIFACT REMOVAL: S<25, 50<V<200 detection",
                    "‚úÖ SHARP EDGE REFINEMENT: k=150 sigmoid, threshold=0.5",
                    "‚úÖ MULTI-COLOR SPACE HOLE DETECTION: RGB + HSV + LAB",
                    "‚úÖ ENCLOSED REGION DETECTION: For inner ring holes",
                    "‚úÖ CONFIDENCE SCORING: Multi-criteria (brightness, saturation, shape, etc.)",
                    "‚úÖ DISTANCE-BASED TRANSITIONS: Smooth hole edges",
                    "‚úÖ FINAL CLEANUP: Remove components < 0.01% of image",
                    "‚úÖ MATCHED WITH ENHANCEMENT: Using same V3 Enhanced removal",
                    "‚úÖ OTHER PATTERN: Now with 5% white overlay",
                    "‚úÖ 005 FILES: Ring-on-finger shot with shadow and rotation"
                ],
                "thumbnail_method": "Proportional resize (no aggressive cropping)",
                "processing_order": "1.U2Net-Ultra-V3-Enhanced ‚Üí 2.White Balance ‚Üí 3.Pattern Enhancement ‚Üí 4.Resize ‚Üí 5.SwinIR ‚Üí 6.Ring Holes",
                "edge_detection": "ULTRA PRECISE V3 ENHANCED (6-method combination)",
                "korean_support": "ENHANCED with font caching",
                "expected_input": "2000x2600 (any format)",
                "output_size": "1000x1300",
                "output_format": "PNG with full transparency (RGB for 005 files)",
                "transparency_info": "Full RGBA transparency preserved - NO background or shadows (except 005 files)",
                "white_overlay": "AC: 20% | AB: 16% | Other: 5%",
                "brightness_adjustments": "AC/AB: 1.03 | Other: 1.09",
                "contrast_final": "1.1",
                "sharpness_final": "Other: 1.5 ‚Üí Final: 1.8",
                "quality": "95",
                "google_script_compatibility": "Base64 WITH padding - FIXED",
                "metal_colors": "Yellow Gold, Rose Gold, White Gold, Antique Gold",
                "enhancement_matching": "FULLY MATCHED with Enhancement Handler V3 Enhanced",
                "shadow_elimination": "ENHANCED with aggressive detection and removal",
                "finger_shot_005": "Automatic ring-on-finger creation for 005 files"
            }
        }
        
    except Exception as e:
        logger.error(f"Error: {str(e)}")
        import traceback
        
        return {
            "output": {
                "error": str(e),
                "status": "failed",
                "version": VERSION,
                "traceback": traceback.format_exc()
            }
        }

# RunPod handler
runpod.serverless.start({"handler": handler})
