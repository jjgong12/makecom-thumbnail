import runpod
import os
import base64
import numpy as np
from io import BytesIO
from PIL import Image, ImageEnhance, ImageFilter, ImageDraw, ImageFont
import requests
import logging
import re
import replicate
import string
import cv2

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

################################
# THUMBNAIL HANDLER - 1000x1300
# VERSION: V22-Ultra-Precise-Transparent
################################

VERSION = "V22-Ultra-Precise-Transparent"

# ===== GLOBAL INITIALIZATION =====
REPLICATE_API_TOKEN = os.environ.get('REPLICATE_API_TOKEN')
REPLICATE_CLIENT = None

if REPLICATE_API_TOKEN:
    try:
        REPLICATE_CLIENT = replicate.Client(api_token=REPLICATE_API_TOKEN)
        logger.info("âœ… Replicate client initialized")
    except Exception as e:
        logger.error(f"âŒ Failed to initialize Replicate: {e}")

# Global rembg session with U2Net
REMBG_SESSION = None

def init_rembg_session():
    """Initialize rembg session with U2Net for faster processing"""
    global REMBG_SESSION
    if REMBG_SESSION is None:
        try:
            from rembg import new_session
            # Use U2Net for faster processing
            REMBG_SESSION = new_session('u2net')
            logger.info("âœ… U2Net session initialized for faster processing")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize rembg: {e}")
            REMBG_SESSION = None
    return REMBG_SESSION

# Initialize on module load
init_rembg_session()

def download_korean_font():
    """Download Korean font for text rendering - IMPROVED"""
    try:
        font_path = '/tmp/NanumGothic.ttf'
        
        # If font exists, verify it works with Korean text
        if os.path.exists(font_path):
            try:
                test_font = ImageFont.truetype(font_path, 20, encoding='utf-8')
                img_test = Image.new('RGB', (100, 100), 'white')
                draw_test = ImageDraw.Draw(img_test)
                draw_test.text((10, 10), "í…ŒìŠ¤íŠ¸", font=test_font, fill='black')
                logger.info("âœ… Korean font verified and working")
                return font_path
            except Exception as e:
                logger.error(f"Font verification failed: {e}")
                os.remove(font_path)
        
        # Download URLs with backup options
        font_urls = [
            'https://github.com/naver/nanumfont/raw/master/fonts/NanumFontSetup_TTF_GOTHIC/NanumGothic.ttf',
            'https://cdn.jsdelivr.net/gh/naver/nanumfont@master/fonts/NanumFontSetup_TTF_GOTHIC/NanumGothic.ttf',
            'https://github.com/naver/nanumfont/raw/master/fonts/NanumFontSetup_TTF_GOTHIC/NanumGothicBold.ttf'
        ]
        
        for url in font_urls:
            try:
                logger.info(f"Downloading font from: {url}")
                response = requests.get(url, timeout=30)
                if response.status_code == 200 and len(response.content) > 100000:
                    with open(font_path, 'wb') as f:
                        f.write(response.content)
                    
                    # Verify the font works
                    test_font = ImageFont.truetype(font_path, 20, encoding='utf-8')
                    logger.info("âœ… Korean font downloaded successfully")
                    return font_path
            except Exception as e:
                logger.error(f"Failed to download from {url}: {e}")
                continue
        
        logger.error("âŒ Failed to download Korean font from all sources")
        return None
    except Exception as e:
        logger.error(f"Font download error: {e}")
        return None

def get_font(size, korean_font_path=None):
    """Get font with proper encoding"""
    if korean_font_path and os.path.exists(korean_font_path):
        try:
            return ImageFont.truetype(korean_font_path, size, encoding='utf-8')
        except Exception as e:
            logger.error(f"Font loading error: {e}")
    
    # Fallback to default
    try:
        return ImageFont.load_default()
    except:
        return None

def safe_draw_text(draw, position, text, font, fill):
    """Safely draw text with proper encoding"""
    try:
        if text and font:
            # Ensure text is properly encoded
            if isinstance(text, bytes):
                text = text.decode('utf-8')
            draw.text(position, str(text), font=font, fill=fill)
    except Exception as e:
        logger.error(f"Text drawing error: {e}")
        # Fallback to simple text
        try:
            draw.text(position, "[Text Error]", font=font, fill=fill)
        except:
            pass

def get_text_size(draw, text, font):
    """Get text size compatible with different PIL versions"""
    try:
        bbox = draw.textbbox((0, 0), text, font=font)
        return bbox[2] - bbox[0], bbox[3] - bbox[1]
    except AttributeError:
        return draw.textsize(text, font=font)

def auto_crop_transparent(image):
    """Auto-crop transparent borders from image with padding"""
    if image.mode != 'RGBA':
        image = image.convert('RGBA')
    
    data = np.array(image)
    alpha = data[:,:,3]
    
    non_transparent = np.where(alpha > 10)
    
    if len(non_transparent[0]) == 0:
        return image
    
    min_y = non_transparent[0].min()
    max_y = non_transparent[0].max()
    min_x = non_transparent[1].min()
    max_x = non_transparent[1].max()
    
    padding = 10
    min_y = max(0, min_y - padding)
    max_y = min(data.shape[0] - 1, max_y + padding)
    min_x = max(0, min_x - padding)
    max_x = min(data.shape[1] - 1, max_x + padding)
    
    cropped = image.crop((min_x, min_y, max_x + 1, max_y + 1))
    return cropped

def apply_enhanced_metal_color(image, metal_color, strength=0.3, color_id=""):
    """Apply enhanced metal color effect with special handling for white and rose"""
    if image.mode != 'RGBA':
        image = image.convert('RGBA')
    
    r, g, b, a = image.split()
    
    r_array = np.array(r, dtype=np.float32)
    g_array = np.array(g, dtype=np.float32)
    b_array = np.array(b, dtype=np.float32)
    a_array = np.array(a)
    
    mask = a_array > 0
    
    if mask.any():
        luminance = (0.299 * r_array + 0.587 * g_array + 0.114 * b_array) / 255.0
        
        metal_r, metal_g, metal_b = [c/255.0 for c in metal_color]
        
        if color_id == "white":
            brightness_boost = 1.05
            r_array[mask] = np.clip(r_array[mask] * brightness_boost, 0, 255)
            g_array[mask] = np.clip(g_array[mask] * brightness_boost, 0, 255)
            b_array[mask] = np.clip(b_array[mask] * brightness_boost, 0, 255)
        
        elif color_id == "rose":
            highlight_mask = luminance > 0.85
            shadow_mask = luminance < 0.15
            midtone_mask = ~highlight_mask & ~shadow_mask & mask
            
            if midtone_mask.any():
                blend_factor = 0.5
                r_array[midtone_mask] = r_array[midtone_mask] * (1 - blend_factor) + (255 * luminance[midtone_mask]) * blend_factor
                g_array[midtone_mask] = g_array[midtone_mask] * (1 - blend_factor) + (160 * luminance[midtone_mask]) * blend_factor
                b_array[midtone_mask] = b_array[midtone_mask] * (1 - blend_factor) + (120 * luminance[midtone_mask]) * blend_factor
            
            if highlight_mask.any():
                r_array[highlight_mask] = np.clip(r_array[highlight_mask] * 0.5 + 255 * 0.5, 0, 255)
                g_array[highlight_mask] = np.clip(g_array[highlight_mask] * 0.5 + 160 * 0.5, 0, 255)
                b_array[highlight_mask] = np.clip(b_array[highlight_mask] * 0.5 + 120 * 0.5, 0, 255)
            
            if shadow_mask.any():
                r_array[shadow_mask] = r_array[shadow_mask] * 0.8 + 50 * 0.2
                g_array[shadow_mask] = g_array[shadow_mask] * 0.8 + 30 * 0.2
                b_array[shadow_mask] = b_array[shadow_mask] * 0.8 + 20 * 0.2
        
        else:
            highlight_mask = luminance > 0.85
            shadow_mask = luminance < 0.15
            midtone_mask = ~highlight_mask & ~shadow_mask & mask
            
            if midtone_mask.any():
                blend_factor = strength * 2.0
                r_array[midtone_mask] = r_array[midtone_mask] * (1 - blend_factor) + (metal_r * 255 * luminance[midtone_mask]) * blend_factor
                g_array[midtone_mask] = g_array[midtone_mask] * (1 - blend_factor) + (metal_g * 255 * luminance[midtone_mask]) * blend_factor
                b_array[midtone_mask] = b_array[midtone_mask] * (1 - blend_factor) + (metal_b * 255 * luminance[midtone_mask]) * blend_factor
            
            if highlight_mask.any():
                tint_factor = strength * 0.5
                r_array[highlight_mask] = r_array[highlight_mask] * (1 - tint_factor) + (metal_r * 255) * tint_factor
                g_array[highlight_mask] = g_array[highlight_mask] * (1 - tint_factor) + (metal_g * 255) * tint_factor
                b_array[highlight_mask] = b_array[highlight_mask] * (1 - tint_factor) + (metal_b * 255) * tint_factor
            
            if shadow_mask.any():
                shadow_tint = strength * 0.2
                r_array[shadow_mask] = r_array[shadow_mask] * (1 - shadow_tint) + (metal_r * r_array[shadow_mask]) * shadow_tint
                g_array[shadow_mask] = g_array[shadow_mask] * (1 - shadow_tint) + (metal_g * g_array[shadow_mask]) * shadow_tint
                b_array[shadow_mask] = b_array[shadow_mask] * (1 - shadow_tint) + (metal_b * b_array[shadow_mask]) * shadow_tint
    
    r_array = np.clip(r_array, 0, 255)
    g_array = np.clip(g_array, 0, 255)
    b_array = np.clip(b_array, 0, 255)
    
    r_new = Image.fromarray(r_array.astype(np.uint8))
    g_new = Image.fromarray(g_array.astype(np.uint8))
    b_new = Image.fromarray(b_array.astype(np.uint8))
    
    return Image.merge('RGBA', (r_new, g_new, b_new, a))

def create_color_section(ring_image, width=1200):
    """Create COLOR section with 4 metal variations"""
    logger.info("Creating COLOR section")
    
    height = 850
    
    section_img = Image.new('RGB', (width, height), '#FFFFFF')
    draw = ImageDraw.Draw(section_img)
    
    korean_font_path = download_korean_font()
    title_font = get_font(56, korean_font_path)
    label_font = get_font(24, korean_font_path)
    
    # Title
    title = "COLOR"
    title_width, _ = get_text_size(draw, title, title_font)
    safe_draw_text(draw, (width//2 - title_width//2, 60), title, title_font, (40, 40, 40))
    
    # Remove background from ring image with ULTRA PRECISE removal
    ring_no_bg = None
    if ring_image:
        try:
            logger.info("Removing background from ring image with ULTRA PRECISE method")
            ring_no_bg = u2net_ultra_precise_removal(ring_image)
            if ring_no_bg.mode != 'RGBA':
                ring_no_bg = ring_no_bg.convert('RGBA')
            ring_no_bg = auto_crop_transparent(ring_no_bg)
            logger.info("Background removed successfully with ultra precision")
        except Exception as e:
            logger.error(f"Failed to remove background: {e}")
            ring_no_bg = ring_image.convert('RGBA') if ring_image else None
    
    # Color definitions
    colors = [
        ("yellow", "YELLOW", (255, 200, 50), 0.3),
        ("rose", "ROSE", (255, 160, 120), 0.35),
        ("white", "WHITE", (255, 255, 255), 0.0),
        ("antique", "ANTIQUE", (245, 235, 225), 0.1)
    ]
    
    # Grid layout
    grid_size = 260
    padding = 60
    start_x = (width - (grid_size * 2 + padding)) // 2
    start_y = 160
    
    for i, (color_id, label, color_rgb, strength) in enumerate(colors):
        row = i // 2
        col = i % 2
        
        x = start_x + col * (grid_size + padding)
        y = start_y + row * (grid_size + 100)
        
        # Create container
        container = Image.new('RGBA', (grid_size, grid_size), (252, 252, 252, 255))
        container_draw = ImageDraw.Draw(container)
        
        # Border
        container_draw.rectangle([0, 0, grid_size-1, grid_size-1], 
                                fill=None, outline=(240, 240, 240), width=1)
        
        if ring_no_bg:
            try:
                # Copy ring and apply color
                ring_copy = ring_no_bg.copy()
                max_size = int(grid_size * 0.7)
                ring_copy.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                
                # Apply color
                ring_tinted = apply_enhanced_metal_color(ring_copy, color_rgb, strength, color_id)
                
                # Center placement
                paste_x = (grid_size - ring_tinted.width) // 2
                paste_y = (grid_size - ring_tinted.height) // 2
                container.paste(ring_tinted, (paste_x, paste_y), ring_tinted)
                
                logger.info(f"Applied {color_id} color")
                
            except Exception as e:
                logger.error(f"Error applying color {color_id}: {e}")
        
        # Paste container to section image
        section_img.paste(container, (x, y))
        
        # Add label
        label_width, _ = get_text_size(draw, label, label_font)
        safe_draw_text(draw, (x + grid_size//2 - label_width//2, y + grid_size + 20), 
                     label, label_font, (80, 80, 80))
    
    logger.info(f"COLOR section created: {width}x{height}")
    return section_img

def u2net_ultra_precise_removal(image: Image.Image) -> Image.Image:
    """ULTRA PRECISE U2Net background removal with advanced edge detection"""
    try:
        from rembg import remove
        
        global REMBG_SESSION
        if REMBG_SESSION is None:
            REMBG_SESSION = init_rembg_session()
            if REMBG_SESSION is None:
                return image
        
        logger.info("ğŸ”· U2Net ULTRA PRECISE Background Removal V22")
        
        # Pre-process image for better edge detection
        # Apply slight contrast enhancement before removal
        contrast = ImageEnhance.Contrast(image)
        image_enhanced = contrast.enhance(1.1)
        
        # Save image to buffer
        buffered = BytesIO()
        image_enhanced.save(buffered, format="PNG")
        buffered.seek(0)
        img_data = buffered.getvalue()
        
        # Apply U2Net removal with ULTRA PRECISE settings
        output = remove(
            img_data,
            session=REMBG_SESSION,
            alpha_matting=True,
            alpha_matting_foreground_threshold=280,  # Even higher for better edges
            alpha_matting_background_threshold=0,
            alpha_matting_erode_size=0,
            only_mask=False,
            post_process_mask=True  # Enable post-processing
        )
        
        result_image = Image.open(BytesIO(output))
        
        if result_image.mode != 'RGBA':
            return result_image
        
        # ULTRA PRECISE edge refinement
        r, g, b, a = result_image.split()
        alpha_array = np.array(a, dtype=np.uint8)
        original_alpha = alpha_array.copy()
        
        # Convert to float for processing
        alpha_float = alpha_array.astype(np.float32) / 255.0
        
        # Stage 1: Advanced edge detection using Sobel
        rgb_array = np.array(result_image.convert('RGB'), dtype=np.uint8)
        gray = cv2.cvtColor(rgb_array, cv2.COLOR_RGB2GRAY)
        
        # Sobel edge detection for more precise edges
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        edge_magnitude = np.sqrt(sobelx**2 + sobely**2)
        edge_magnitude = (edge_magnitude / edge_magnitude.max() * 255).astype(np.uint8)
        
        # Stage 2: Create edge mask
        edge_mask = edge_magnitude > 30
        edge_dilated = cv2.dilate(edge_mask.astype(np.uint8), np.ones((3,3)), iterations=2)
        
        # Stage 3: Apply guided filter for ultra-smooth edges
        try:
            # Normalize gray for guided filter
            gray_float = gray.astype(np.float32) / 255.0
            
            # Multiple passes of guided filter with different parameters
            alpha_guided1 = cv2.ximgproc.guidedFilter(
                guide=gray_float,
                src=alpha_float,
                radius=1,
                eps=0.0001  # Very small epsilon for maximum edge preservation
            )
            
            alpha_guided2 = cv2.ximgproc.guidedFilter(
                guide=gray_float,
                src=alpha_guided1,
                radius=3,
                eps=0.001
            )
            
            # Blend the two guided results
            alpha_float = alpha_guided1 * 0.7 + alpha_guided2 * 0.3
            
        except AttributeError:
            # Fallback to bilateral filter
            alpha_uint8 = (alpha_float * 255).astype(np.uint8)
            alpha_bilateral = cv2.bilateralFilter(alpha_uint8, 5, 75, 75)
            alpha_float = alpha_bilateral.astype(np.float32) / 255.0
        
        # Stage 4: Ultra-precise threshold with smooth gradients
        # Create smooth transition using sigmoid function
        k = 50  # Steepness of transition
        threshold = 0.5
        alpha_sigmoid = 1 / (1 + np.exp(-k * (alpha_float - threshold)))
        
        # Stage 5: Edge-aware smoothing
        # Only smooth non-edge areas
        alpha_smooth = alpha_sigmoid.copy()
        non_edge_mask = ~edge_dilated.astype(bool)
        if np.any(non_edge_mask):
            # Apply gentle smoothing to non-edge areas
            alpha_smooth_temp = cv2.GaussianBlur(alpha_sigmoid, (5, 5), 1.0)
            alpha_smooth[non_edge_mask] = alpha_smooth_temp[non_edge_mask]
        
        # Stage 6: Hair and fine detail preservation
        # Detect fine details using high-pass filter
        alpha_highpass = alpha_float - cv2.GaussianBlur(alpha_float, (7, 7), 2.0)
        fine_details = np.abs(alpha_highpass) > 0.05
        
        # Preserve fine details
        alpha_smooth[fine_details] = alpha_float[fine_details]
        
        # Stage 7: Remove small artifacts while preserving tiny details
        alpha_binary = (alpha_smooth > 0.5).astype(np.uint8)
        num_labels, labels = cv2.connectedComponents(alpha_binary)
        
        if num_labels > 2:
            sizes = [np.sum(labels == i) for i in range(1, num_labels)]
            if sizes:
                # More aggressive artifact removal
                min_size = int(alpha_array.size * 0.0002)  # 0.02% of image
                valid_labels = [i+1 for i, size in enumerate(sizes) if size > min_size]
                
                # Create valid mask
                valid_mask = np.zeros_like(alpha_binary, dtype=bool)
                for label in valid_labels:
                    valid_mask |= (labels == label)
                
                # Apply mask but preserve edges
                alpha_smooth[~valid_mask & ~edge_dilated.astype(bool)] = 0
        
        # Stage 8: Final polish with edge enhancement
        # Enhance edges slightly
        edge_enhancement = 1.2
        alpha_smooth[edge_dilated.astype(bool)] *= edge_enhancement
        
        # Convert back to uint8
        alpha_array = np.clip(alpha_smooth * 255, 0, 255).astype(np.uint8)
        
        # Stage 9: Feather edges for natural look
        # Create feathered edge
        kernel_feather = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        alpha_eroded = cv2.erode(alpha_array, kernel_feather, iterations=1)
        alpha_dilated = cv2.dilate(alpha_array, kernel_feather, iterations=1)
        
        # Blend for feathering
        feather_mask = (alpha_dilated > 0) & (alpha_eroded < 255)
        if np.any(feather_mask):
            alpha_array[feather_mask] = ((alpha_array[feather_mask].astype(np.float32) + 
                                         alpha_eroded[feather_mask].astype(np.float32)) / 2).astype(np.uint8)
        
        logger.info("âœ… ULTRA PRECISE background removal complete")
        
        a_new = Image.fromarray(alpha_array)
        return Image.merge('RGBA', (r, g, b, a_new))
        
    except Exception as e:
        logger.error(f"U2Net removal failed: {e}")
        return image

def ensure_ring_holes_transparent_ultra(image: Image.Image) -> Image.Image:
    """ULTRA PRECISE ring hole detection with maximum accuracy"""
    if image.mode != 'RGBA':
        return image
    
    logger.info("ğŸ” ULTRA PRECISE Ring Hole Detection V22")
    
    r, g, b, a = image.split()
    alpha_array = np.array(a, dtype=np.uint8)
    rgb_array = np.array(image.convert('RGB'), dtype=np.uint8)
    
    h, w = alpha_array.shape
    
    # Convert to HSV for better color analysis
    hsv = cv2.cvtColor(rgb_array, cv2.COLOR_RGB2HSV)
    h_channel, s_channel, v_channel = cv2.split(hsv)
    
    # Multi-criteria hole detection
    # 1. Very bright areas (potential holes)
    very_bright = v_channel > 240
    
    # 2. Low saturation (grayish/white areas)
    low_saturation = s_channel < 30
    
    # 3. Current alpha holes
    alpha_holes = alpha_array < 50
    
    # 4. Combine all criteria
    potential_holes = (very_bright & low_saturation) | alpha_holes
    
    # Clean up noise
    kernel_clean = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    potential_holes = cv2.morphologyEx(potential_holes.astype(np.uint8), cv2.MORPH_OPEN, kernel_clean)
    potential_holes = cv2.morphologyEx(potential_holes, cv2.MORPH_CLOSE, kernel_clean)
    
    # Find connected components
    num_labels, labels = cv2.connectedComponents(potential_holes)
    
    holes_mask = np.zeros_like(alpha_array, dtype=np.float32)
    
    # Analyze each component
    for label in range(1, num_labels):
        component = (labels == label)
        component_size = np.sum(component)
        
        # Size filtering - adjust for ring holes
        if h * w * 0.0001 < component_size < h * w * 0.2:
            # Get component properties
            coords = np.where(component)
            if len(coords[0]) == 0:
                continue
                
            min_y, max_y = coords[0].min(), coords[0].max()
            min_x, max_x = coords[1].min(), coords[1].max()
            
            comp_width = max_x - min_x
            comp_height = max_y - min_y
            
            if comp_height == 0:
                continue
            
            # Multiple validation criteria
            aspect_ratio = comp_width / comp_height
            
            # 1. Shape validation (ring holes can be various shapes)
            shape_valid = 0.2 < aspect_ratio < 5.0
            
            # 2. Position validation (usually in center area)
            center_y, center_x = (min_y + max_y) / 2, (min_x + max_x) / 2
            center_distance = np.sqrt((center_x - w/2)**2 + (center_y - h/2)**2)
            position_valid = center_distance < max(w, h) * 0.45
            
            # 3. Color consistency check
            component_pixels = rgb_array[component]
            if len(component_pixels) > 0:
                # Check brightness
                brightness = np.mean(component_pixels)
                brightness_std = np.std(component_pixels)
                
                brightness_valid = brightness > 230
                consistency_valid = brightness_std < 25
                
                # 4. Circularity check
                component_uint8 = component.astype(np.uint8) * 255
                contours, _ = cv2.findContours(component_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                circularity_valid = False
                if contours:
                    contour = contours[0]
                    area = cv2.contourArea(contour)
                    perimeter = cv2.arcLength(contour, True)
                    if perimeter > 0:
                        circularity = 4 * np.pi * area / (perimeter * perimeter)
                        circularity_valid = circularity > 0.3
                
                # 5. Edge smoothness check
                edges = cv2.Canny(component_uint8, 50, 150)
                edge_ratio = np.sum(edges > 0) / max(1, perimeter)
                smoothness_valid = edge_ratio < 2.0
                
                # Calculate confidence score
                confidence = 0.0
                if brightness_valid: confidence += 0.35
                if consistency_valid: confidence += 0.25
                if position_valid: confidence += 0.15
                if circularity_valid: confidence += 0.15
                if smoothness_valid: confidence += 0.10
                
                # Apply hole mask if confident
                if confidence > 0.45 and shape_valid:
                    holes_mask[component] = 255
                    logger.info(f"Hole detected with confidence: {confidence:.2f}")
    
    # Apply holes if any detected
    if np.any(holes_mask > 0):
        # Smooth hole edges
        holes_mask_smooth = cv2.GaussianBlur(holes_mask, (5, 5), 1.0)
        
        # Create transition zone
        kernel_dilate = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        holes_dilated = cv2.dilate(holes_mask, kernel_dilate, iterations=1)
        transition_zone = (holes_dilated > 0) & (holes_mask < 255)
        
        # Apply graduated transparency
        alpha_float = alpha_array.astype(np.float32)
        
        # Full transparency in hole centers
        alpha_float[holes_mask_smooth > 200] = 0
        
        # Graduated transparency in transition
        if np.any(transition_zone):
            transition_alpha = 1 - (holes_mask_smooth[transition_zone] / 255)
            alpha_float[transition_zone] *= transition_alpha
        
        alpha_array = np.clip(alpha_float, 0, 255).astype(np.uint8)
        
        logger.info("âœ… Ring holes made transparent")
    
    a_new = Image.fromarray(alpha_array)
    return Image.merge('RGBA', (r, g, b, a_new))

def process_color_section(job):
    """Process COLOR section special mode"""
    logger.info("Processing COLOR section special mode")
    
    try:
        # Find image data
        image_data = find_input_data_fast(job)
        
        if not image_data:
            return {
                "output": {
                    "error": "No image data found for COLOR section",
                    "status": "error",
                    "version": VERSION
                }
            }
        
        # Decode and open image
        image_bytes = decode_base64_fast(image_data)
        ring_image = Image.open(BytesIO(image_bytes))
        
        # Create COLOR section
        color_section = create_color_section(ring_image, width=1200)
        
        # Convert to base64
        buffered = BytesIO()
        color_section.save(buffered, format="PNG", optimize=False)
        buffered.seek(0)
        section_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
        section_base64_no_padding = section_base64.rstrip('=')
        
        logger.info("COLOR section created successfully")
        
        return {
            "output": {
                "thumbnail": section_base64_no_padding,
                "size": list(color_section.size),
                "section_type": "color",
                "special_mode": "color_section",
                "filename": "ac_wedding_011.png",
                "file_number": "011",
                "version": VERSION,
                "status": "success",
                "format": "base64_no_padding",
                "colors_generated": ["YELLOW", "ROSE", "WHITE", "ANTIQUE"],
                "background_removal": "ULTRA_PRECISE"
            }
        }
        
    except Exception as e:
        logger.error(f"Error creating COLOR section: {str(e)}")
        import traceback
        
        return {
            "output": {
                "error": str(e),
                "status": "error",
                "version": VERSION,
                "traceback": traceback.format_exc()
            }
        }

# Add all other helper functions from the original code...
def find_input_data_fast(data):
    """Fast input data extraction"""
    if isinstance(data, str) and len(data) > 50:
        return {'image': data}
    
    if isinstance(data, dict):
        priority_keys = ['image', 'image_base64', 'enhanced_image', 'base64', 'img']
        
        for key in priority_keys:
            if key in data and isinstance(data[key], str) and len(data[key]) > 50:
                return {key: data[key]}
        
        for key in ['input', 'data']:
            if key in data and isinstance(data[key], dict):
                result = find_input_data_fast(data[key])
                if result:
                    return result
        
        for i in range(5):
            if str(i) in data and isinstance(data[str(i)], str) and len(data[str(i)]) > 50:
                return {'image': data[str(i)]}
    
    return data

def find_filename_fast(data):
    """Fast filename extraction"""
    if isinstance(data, dict):
        for key in ['filename', 'file_name', 'name']:
            if key in data and isinstance(data[key], str):
                return data[key]
        
        if 'input' in data and isinstance(data['input'], dict):
            for key in ['filename', 'file_name', 'name']:
                if key in data['input']:
                    return data['input'][key]
    
    return None

def generate_thumbnail_filename(original_filename, image_index):
    """Generate thumbnail filename with fixed numbers"""
    if not original_filename:
        return f"thumbnail_{image_index:03d}.jpg"
    
    # Fixed thumbnail numbers: 007, 009, 010
    thumbnail_numbers = {1: "007", 2: "009", 3: "010"}
    
    new_filename = original_filename
    pattern = r'(_\d{3})'
    if re.search(pattern, new_filename):
        new_filename = re.sub(pattern, f'_{thumbnail_numbers.get(image_index, "007")}', new_filename)
    else:
        name_parts = new_filename.split('.')
        name_parts[0] += f'_{thumbnail_numbers.get(image_index, "007")}'
        new_filename = '.'.join(name_parts)
    
    return new_filename

def base64_to_image_fast(base64_string):
    """Fast base64 to image conversion"""
    try:
        if not base64_string or len(base64_string) < 50:
            raise ValueError("Invalid base64")
        
        if 'base64,' in base64_string:
            base64_string = base64_string.split('base64,')[-1]
        
        base64_string = ''.join(base64_string.split())
        
        valid_chars = set(string.ascii_letters + string.digits + '+/=')
        base64_string = ''.join(c for c in base64_string if c in valid_chars)
        
        no_pad = base64_string.rstrip('=')
        
        try:
            img_data = base64.b64decode(no_pad, validate=False)
            return Image.open(BytesIO(img_data))
        except:
            padding = (4 - len(no_pad) % 4) % 4
            padded = no_pad + ('=' * padding)
            img_data = base64.b64decode(padded, validate=False)
            return Image.open(BytesIO(img_data))
            
    except Exception as e:
        logger.error(f"Base64 decode error: {str(e)}")
        raise ValueError(f"Invalid base64: {str(e)}")

def decode_base64_fast(base64_str: str) -> bytes:
    """FAST base64 decode"""
    try:
        if not base64_str or len(base64_str) < 50:
            raise ValueError("Invalid base64 string")
        
        if 'base64,' in base64_str:
            base64_str = base64_str.split('base64,')[-1]
        
        base64_str = ''.join(base64_str.split())
        
        valid_chars = set(string.ascii_letters + string.digits + '+/=')
        base64_str = ''.join(c for c in base64_str if c in valid_chars)
        
        no_pad = base64_str.rstrip('=')
        
        try:
            decoded = base64.b64decode(no_pad, validate=False)
            return decoded
        except:
            padding_needed = (4 - len(no_pad) % 4) % 4
            padded = no_pad + ('=' * padding_needed)
            decoded = base64.b64decode(padded, validate=False)
            return decoded
            
    except Exception as e:
        logger.error(f"Base64 decode error: {str(e)}")
        raise ValueError(f"Invalid base64 data: {str(e)}")

def detect_pattern_type(filename: str) -> str:
    """Detect pattern type - Updated with AB pattern"""
    if not filename:
        return "other"
    
    filename_lower = filename.lower()
    
    if 'ac_' in filename_lower:
        return "ac_pattern"
    elif 'ab_' in filename_lower:
        return "ab_pattern"
    else:
        return "other"

def create_background(size, color="#E0DADC", style="gradient"):
    """Create natural gray background"""
    width, height = size
    
    if style == "gradient":
        background = Image.new('RGB', size, color)
        bg_array = np.array(background, dtype=np.float32)
        
        y, x = np.ogrid[:height, :width]
        center_x, center_y = width / 2, height / 2
        distance = np.sqrt((x - center_x)**2 + (y - center_y)**2) / max(width, height)
        
        gradient = 1 - (distance * 0.05)
        gradient = np.clip(gradient, 0.95, 1.0)
        
        bg_array *= gradient[:, :, np.newaxis]
        
        return Image.fromarray(bg_array.astype(np.uint8))
    else:
        return Image.new('RGB', size, color)

def create_thumbnail_proportional(image, target_width=1000, target_height=1300):
    """Create thumbnail with proper proportional sizing - Fixed version"""
    original_width, original_height = image.size
    
    logger.info(f"Creating proportional thumbnail from {original_width}x{original_height} to {target_width}x{target_height}")
    
    # For 2000x2600 -> 1000x1300, it's exactly 50% resize
    # Just resize directly without complex cropping
    if original_width == 2000 and original_height == 2600:
        logger.info("Direct 50% resize for standard input size")
        return image.resize((target_width, target_height), Image.Resampling.LANCZOS)
    
    # For other sizes, maintain aspect ratio
    scale_x = target_width / original_width
    scale_y = target_height / original_height
    scale = min(scale_x, scale_y)
    
    new_width = int(original_width * scale)
    new_height = int(original_height * scale)
    
    # Resize first
    resized = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
    
    # Center crop if needed
    if new_width != target_width or new_height != target_height:
        left = (new_width - target_width) // 2
        top = (new_height - target_height) // 2
        right = left + target_width
        bottom = top + target_height
        resized = resized.crop((left, top, right, bottom))
    
    return resized

def composite_with_natural_blend(image, background_color="#E0DADC"):
    """SIMPLIFIED natural composite with edge blending"""
    if image.mode != 'RGBA':
        return image
    
    logger.info("ğŸ¨ Simplified background composite")
    
    # Create background
    background = create_background(image.size, background_color, style="gradient")
    
    # Get alpha channel
    r, g, b, a = image.split()
    alpha_array = np.array(a, dtype=np.float32) / 255.0
    
    # Simple edge softening
    alpha_soft = cv2.GaussianBlur(alpha_array, (3, 3), 1.0)
    
    # Find edges
    edges = cv2.Canny((alpha_array * 255).astype(np.uint8), 50, 150)
    edge_mask = cv2.dilate(edges, np.ones((5, 5)), iterations=1) > 0
    
    # Blend original and soft alpha at edges only
    alpha_final = alpha_array.copy()
    alpha_final[edge_mask] = alpha_soft[edge_mask]
    
    # Convert images to arrays
    fg_array = np.array(image.convert('RGB'), dtype=np.float32)
    bg_array = np.array(background, dtype=np.float32)
    
    # Simple composite
    result = fg_array * alpha_final[:,:,np.newaxis] + bg_array * (1 - alpha_final[:,:,np.newaxis])
    
    return Image.fromarray(np.clip(result, 0, 255).astype(np.uint8))

def apply_swinir_thumbnail(image: Image.Image) -> Image.Image:
    """Apply SwinIR enhancement for thumbnails while preserving transparency"""
    if not REPLICATE_CLIENT:
        logger.warning("SwinIR skipped - no Replicate client")
        return image
    
    try:
        logger.info("ğŸ¨ Applying SwinIR enhancement with transparency support")
        
        # Check if image has transparency
        if image.mode == 'RGBA':
            r, g, b, a = image.split()
            rgb_image = Image.merge('RGB', (r, g, b))
            has_alpha = True
        else:
            rgb_image = image
            has_alpha = False
        
        buffered = BytesIO()
        rgb_image.save(buffered, format="PNG", optimize=False)
        buffered.seek(0)
        img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
        img_data_url = f"data:image/png;base64,{img_base64}"
        
        output = REPLICATE_CLIENT.run(
            "jingyunliang/swinir:660d922d33153019e8c263a3bba265de882e7f4f70396546b6c9c8f9d47a021a",
            input={
                "image": img_data_url,
                "task_type": "Real-World Image Super-Resolution",
                "scale": 1,
                "noise_level": 10,
                "jpeg_quality": 50
            }
        )
        
        if output:
            if isinstance(output, str):
                response = requests.get(output)
                enhanced_image = Image.open(BytesIO(response.content))
            else:
                enhanced_image = Image.open(BytesIO(base64.b64decode(output)))
            
            # Recombine with alpha if needed
            if has_alpha:
                r2, g2, b2 = enhanced_image.split()
                enhanced_image = Image.merge('RGBA', (r2, g2, b2, a))
            
            logger.info("âœ… SwinIR enhancement successful with transparency")
            return enhanced_image
            
    except Exception as e:
        logger.warning(f"SwinIR error: {str(e)}")
        
    return image

def enhance_cubic_details_thumbnail_simple(image: Image.Image) -> Image.Image:
    """Enhanced cubic details for thumbnails"""
    contrast = ImageEnhance.Contrast(image)
    image = contrast.enhance(1.08)
    
    image = image.filter(ImageFilter.UnsharpMask(radius=0.3, percent=120, threshold=3))
    
    contrast2 = ImageEnhance.Contrast(image)
    image = contrast2.enhance(1.03)
    
    sharpness = ImageEnhance.Sharpness(image)
    image = sharpness.enhance(1.20)
    
    return image

def auto_white_balance_fast(image: Image.Image) -> Image.Image:
    """Fast white balance"""
    img_array = np.array(image, dtype=np.float32)
    
    sampled = img_array[::15, ::15]
    gray_mask = (
        (np.abs(sampled[:,:,0] - sampled[:,:,1]) < 15) & 
        (np.abs(sampled[:,:,1] - sampled[:,:,2]) < 15) &
        (sampled[:,:,0] > 180)
    )
    
    if np.sum(gray_mask) > 10:
        r_avg = np.mean(sampled[gray_mask, 0])
        g_avg = np.mean(sampled[gray_mask, 1])
        b_avg = np.mean(sampled[gray_mask, 2])
        
        gray_avg = (r_avg + g_avg + b_avg) / 3
        
        img_array[:,:,0] *= (gray_avg / r_avg) if r_avg > 0 else 1
        img_array[:,:,1] *= (gray_avg / g_avg) if g_avg > 0 else 1
        img_array[:,:,2] *= (gray_avg / b_avg) if b_avg > 0 else 1
    
    return Image.fromarray(np.clip(img_array, 0, 255).astype(np.uint8))

def apply_center_spotlight_fast(image: Image.Image, intensity: float = 0.025) -> Image.Image:
    """Fast center spotlight"""
    width, height = image.size
    
    y, x = np.ogrid[:height, :width]
    center_x, center_y = width / 2, height / 2
    distance = np.sqrt((x - center_x)**2 + (y - center_y)**2) / max(width, height)
    
    spotlight_mask = 1 + intensity * np.exp(-distance**2 * 3)
    spotlight_mask = np.clip(spotlight_mask, 1.0, 1.0 + intensity)
    
    img_array = np.array(image, dtype=np.float32)
    img_array *= spotlight_mask[:, :, np.newaxis]
    
    return Image.fromarray(np.clip(img_array, 0, 255).astype(np.uint8))

def apply_wedding_ring_focus_fast(image: Image.Image) -> Image.Image:
    """Enhanced wedding ring focus for thumbnails"""
    image = apply_center_spotlight_fast(image, 0.020)
    
    sharpness = ImageEnhance.Sharpness(image)
    image = sharpness.enhance(1.6)
    
    contrast = ImageEnhance.Contrast(image)
    image = contrast.enhance(1.04)
    
    image = image.filter(ImageFilter.UnsharpMask(radius=0.8, percent=100, threshold=3))
    
    return image

def calculate_quality_metrics_fast(image: Image.Image) -> dict:
    """Fast quality metrics"""
    img_array = np.array(image)[::30, ::30]
    
    r_avg = np.mean(img_array[:,:,0])
    g_avg = np.mean(img_array[:,:,1])
    b_avg = np.mean(img_array[:,:,2])
    
    brightness = (r_avg + g_avg + b_avg) / 3
    
    return {
        "brightness": brightness
    }

def apply_pattern_enhancement_consistent(image, pattern_type):
    """Consistent pattern enhancement with white overlay verification - Updated with AB pattern cool tone"""
    
    if pattern_type == "ac_pattern":
        # Calculate brightness before overlay
        metrics_before = calculate_quality_metrics_fast(image)
        logger.info(f"ğŸ” AC Pattern - Brightness before overlay: {metrics_before['brightness']:.2f}")
        
        # Apply 12% white overlay
        white_overlay = 0.12
        img_array = np.array(image, dtype=np.float32)
        img_array = img_array * (1 - white_overlay) + 255 * white_overlay
        img_array = np.clip(img_array, 0, 255)
        image = Image.fromarray(img_array.astype(np.uint8))
        
        # Verify overlay was applied
        metrics_after = calculate_quality_metrics_fast(image)
        logger.info(f"âœ… AC Pattern - Brightness after 12% overlay: {metrics_after['brightness']:.2f} (increased by {metrics_after['brightness'] - metrics_before['brightness']:.2f})")
        
        brightness = ImageEnhance.Brightness(image)
        image = brightness.enhance(1.005)
        
        color = ImageEnhance.Color(image)
        image = color.enhance(0.98)
    
    elif pattern_type == "ab_pattern":
        # Calculate brightness before overlay
        metrics_before = calculate_quality_metrics_fast(image)
        logger.info(f"ğŸ” AB Pattern - Brightness before overlay: {metrics_before['brightness']:.2f}")
        
        # Apply 5% white overlay
        white_overlay = 0.05
        img_array = np.array(image, dtype=np.float32)
        img_array = img_array * (1 - white_overlay) + 255 * white_overlay
        img_array = np.clip(img_array, 0, 255)
        image = Image.fromarray(img_array.astype(np.uint8))
        
        # Verify overlay was applied
        metrics_after = calculate_quality_metrics_fast(image)
        logger.info(f"âœ… AB Pattern - Brightness after 5% overlay: {metrics_after['brightness']:.2f} (increased by {metrics_after['brightness'] - metrics_before['brightness']:.2f})")
        
        # Cool tone adjustment for AB pattern
        logger.info("â„ï¸ AB Pattern - Applying cool tone adjustment")
        img_array = np.array(image, dtype=np.float32)
        
        # Shift to cool tone by adjusting RGB channels
        img_array[:,:,0] *= 0.96  # Reduce red slightly
        img_array[:,:,1] *= 0.98  # Reduce green very slightly
        img_array[:,:,2] *= 1.02  # Increase blue slightly
        
        # Apply subtle cool color grading
        cool_overlay = np.array([240, 248, 255], dtype=np.float32)  # Alice blue tone
        img_array = img_array * 0.95 + cool_overlay * 0.05
        
        img_array = np.clip(img_array, 0, 255)
        image = Image.fromarray(img_array.astype(np.uint8))
        
        # Reduce saturation for cooler look
        color = ImageEnhance.Color(image)
        image = color.enhance(0.88)  # Reduce saturation by 12%
        
        brightness = ImageEnhance.Brightness(image)
        image = brightness.enhance(1.005)
        
    else:
        brightness = ImageEnhance.Brightness(image)
        image = brightness.enhance(1.08)
        
        color = ImageEnhance.Color(image)
        image = color.enhance(0.99)
        
        sharpness = ImageEnhance.Sharpness(image)
        image = sharpness.enhance(1.5)
    
    image = apply_center_spotlight_fast(image, 0.025)
    image = apply_wedding_ring_focus_fast(image)
    
    # Quality check for ac_pattern
    if pattern_type == "ac_pattern":
        metrics = calculate_quality_metrics_fast(image)
        logger.info(f"ğŸ” AC Pattern - Final brightness check: {metrics['brightness']:.2f}")
        
        if metrics["brightness"] < 235:
            logger.info("âš ï¸ AC Pattern - Brightness too low, applying 15% overlay")
            white_overlay = 0.15
            img_array = np.array(image, dtype=np.float32)
            img_array = img_array * (1 - white_overlay) + 255 * white_overlay
            img_array = np.clip(img_array, 0, 255)
            image = Image.fromarray(img_array.astype(np.uint8))
            
            metrics_final = calculate_quality_metrics_fast(image)
            logger.info(f"âœ… AC Pattern - Final brightness after 15% overlay: {metrics_final['brightness']:.2f}")
    
    # Quality check for ab_pattern
    elif pattern_type == "ab_pattern":
        metrics = calculate_quality_metrics_fast(image)
        logger.info(f"ğŸ” AB Pattern - Final brightness check: {metrics['brightness']:.2f}")
        
        if metrics["brightness"] < 235:
            logger.info("âš ï¸ AB Pattern - Brightness too low, applying 8% overlay")
            white_overlay = 0.08
            img_array = np.array(image, dtype=np.float32)
            img_array = img_array * (1 - white_overlay) + 255 * white_overlay
            img_array = np.clip(img_array, 0, 255)
            image = Image.fromarray(img_array.astype(np.uint8))
            
            metrics_final = calculate_quality_metrics_fast(image)
            logger.info(f"âœ… AB Pattern - Final brightness after 8% overlay: {metrics_final['brightness']:.2f}")
    
    return image

def image_to_base64(image, keep_transparency=True):
    """Convert to base64 without padding - FIXED to preserve transparency"""
    buffered = BytesIO()
    
    # Check if user wants transparent output
    if keep_transparency and image.mode == 'RGBA':
        # Keep RGBA format for transparent images
        logger.info("ğŸ’ Preserving transparency in output")
        image.save(buffered, format='PNG', optimize=False)
    else:
        # Convert to RGB with white background if not keeping transparency
        if image.mode == 'RGBA':
            background = Image.new('RGB', image.size, (255, 255, 255))
            background.paste(image, mask=image.split()[3])
            image = background
        
        image.save(buffered, format='PNG', optimize=False, quality=95)
    
    buffered.seek(0)
    
    return base64.b64encode(buffered.getvalue()).decode().rstrip('=')

def handler(event):
    """Optimized thumbnail handler - V22 with ULTRA Precise Edge Detection and Transparent Output"""
    try:
        logger.info(f"=== Thumbnail {VERSION} Started ===")
        logger.info("ğŸ¯ ULTRA PRECISE MODE: Maximum edge detection enabled")
        logger.info("ğŸ’ TRANSPARENT OUTPUT: Preserving transparency in final image")
        
        # Check for special mode first
        if event.get('special_mode') == 'color_section':
            return process_color_section(event)
        
        # Check if user wants transparent output (default: True for PNG inputs)
        keep_transparency = event.get('keep_transparency', True)
        
        # Normal thumbnail processing continues here...
        image_index = event.get('image_index', 1)
        if isinstance(event.get('input'), dict):
            image_index = event.get('input', {}).get('image_index', image_index)
        
        background_color = '#E0DADC'
        
        filename = find_filename_fast(event)
        input_data = find_input_data_fast(event)
        
        if not input_data:
            raise ValueError("No input data found")
        
        image = None
        priority_keys = ['image', 'image_base64', 'enhanced_image', 'base64']
        
        for key in priority_keys:
            if key in input_data and input_data[key]:
                try:
                    image = base64_to_image_fast(input_data[key])
                    break
                except:
                    continue
        
        if not image:
            raise ValueError("Failed to load image")
        
        # STEP 1: ULTRA PRECISE BACKGROUND REMOVAL (PNG files)
        original_mode = image.mode
        has_transparency = image.mode == 'RGBA'
        needs_background_removal = False
        
        if filename and filename.lower().endswith('.png'):
            logger.info("ğŸ“¸ STEP 1: PNG detected - ULTRA PRECISE background removal")
            image = u2net_ultra_precise_removal(image)
            has_transparency = image.mode == 'RGBA'
            needs_background_removal = True
        
        # Ensure RGBA mode if keeping transparency
        if keep_transparency and has_transparency:
            if image.mode != 'RGBA':
                image = image.convert('RGBA')
        
        # STEP 2: ENHANCEMENT (preserving transparency)
        logger.info("ğŸ¨ STEP 2: Applying enhancements with transparency preservation")
        
        pattern_type = detect_pattern_type(filename)
        
        if image.mode == 'RGBA':
            # Process RGB channels separately
            r, g, b, a = image.split()
            rgb_image = Image.merge('RGB', (r, g, b))
            
            # Apply enhancements to RGB only
            rgb_image = auto_white_balance_fast(rgb_image)
            
            brightness = ImageEnhance.Brightness(rgb_image)
            rgb_image = brightness.enhance(1.08)
            
            contrast = ImageEnhance.Contrast(rgb_image)
            rgb_image = contrast.enhance(1.05)
            
            color = ImageEnhance.Color(rgb_image)
            rgb_image = color.enhance(1.005)
            
            # Recombine with alpha
            r2, g2, b2 = rgb_image.split()
            image = Image.merge('RGBA', (r2, g2, b2, a))
        else:
            # Normal processing for non-transparent images
            image = auto_white_balance_fast(image)
            
            brightness = ImageEnhance.Brightness(image)
            image = brightness.enhance(1.08)
            
            contrast = ImageEnhance.Contrast(image)
            image = contrast.enhance(1.05)
            
            color = ImageEnhance.Color(image)
            image = color.enhance(1.005)
        
        # Create thumbnail with proportional sizing
        thumbnail = create_thumbnail_proportional(image, 1000, 1300)
        
        # STEP 3: SWINIR ENHANCEMENT (preserving transparency)
        logger.info("ğŸš€ STEP 3: Applying SwinIR enhancement with transparency")
        thumbnail = apply_swinir_thumbnail(thumbnail)
        
        thumbnail = enhance_cubic_details_thumbnail_simple(thumbnail)
        
        detected_type = {
            "ac_pattern": "ë¬´ë„ê¸ˆí™”ì´íŠ¸(0.12/0.15)",
            "ab_pattern": "ë¬´ë„ê¸ˆí™”ì´íŠ¸-ì¿¨í†¤(0.05/0.08)",
            "other": "ê¸°íƒ€ìƒ‰ìƒ(no_overlay)"
        }.get(pattern_type, "ê¸°íƒ€ìƒ‰ìƒ")
        
        # Apply pattern enhancement
        if thumbnail.mode == 'RGBA':
            # Apply to RGB channels only
            r, g, b, a = thumbnail.split()
            rgb_thumbnail = Image.merge('RGB', (r, g, b))
            rgb_thumbnail = apply_pattern_enhancement_consistent(rgb_thumbnail, pattern_type)
            r2, g2, b2 = rgb_thumbnail.split()
            thumbnail = Image.merge('RGBA', (r2, g2, b2, a))
        else:
            thumbnail = apply_pattern_enhancement_consistent(thumbnail, pattern_type)
        
        # STEP 4: Ultra precise ring hole detection
        if thumbnail.mode == 'RGBA':
            logger.info("ğŸ” Applying ULTRA PRECISE ring hole detection")
            thumbnail = ensure_ring_holes_transparent_ultra(thumbnail)
        
        # Final adjustments
        if thumbnail.mode == 'RGBA':
            r, g, b, a = thumbnail.split()
            rgb_thumbnail = Image.merge('RGB', (r, g, b))
            
            sharpness = ImageEnhance.Sharpness(rgb_thumbnail)
            rgb_thumbnail = sharpness.enhance(1.5)
            
            brightness = ImageEnhance.Brightness(rgb_thumbnail)
            rgb_thumbnail = brightness.enhance(1.02)
            
            r2, g2, b2 = rgb_thumbnail.split()
            thumbnail = Image.merge('RGBA', (r2, g2, b2, a))
        else:
            sharpness = ImageEnhance.Sharpness(thumbnail)
            thumbnail = sharpness.enhance(1.5)
            
            brightness = ImageEnhance.Brightness(thumbnail)
            thumbnail = brightness.enhance(1.02)
        
        # Convert to base64 - FIXED to preserve transparency
        thumbnail_base64 = image_to_base64(thumbnail, keep_transparency=keep_transparency)
        
        output_filename = generate_thumbnail_filename(filename, image_index)
        
        return {
            "output": {
                "thumbnail": thumbnail_base64,
                "size": list(thumbnail.size),
                "detected_type": detected_type,
                "pattern_type": pattern_type,
                "is_wedding_ring": True,
                "filename": output_filename,
                "original_filename": filename,
                "image_index": image_index,
                "format": "base64_no_padding",
                "version": VERSION,
                "status": "success",
                "swinir_applied": True,
                "swinir_timing": "AFTER resize",
                "png_support": True,
                "has_transparency": thumbnail.mode == 'RGBA',
                "transparency_preserved": keep_transparency and thumbnail.mode == 'RGBA',
                "background_removal": needs_background_removal,
                "background_color": background_color if not keep_transparency else "none",
                "special_modes_available": ["color_section"],
                "file_number_info": {
                    "007": "Thumbnail 1",
                    "009": "Thumbnail 2", 
                    "010": "Thumbnail 3",
                    "011": "COLOR section"
                },
                "optimization_features": [
                    "âœ… TRANSPARENT OUTPUT: PNG with preserved alpha channel",
                    "âœ… ULTRA PRECISE Transparent PNG edge detection",
                    "âœ… Enhanced Korean font support with proper encoding",
                    "âœ… Advanced multi-stage edge refinement",
                    "âœ… Sobel edge detection for precision",
                    "âœ… Multiple guided filter passes",
                    "âœ… Hair and fine detail preservation",
                    "âœ… Feathered edges for natural look",
                    "âœ… Ultra precise ring hole detection",
                    "âœ… Enhanced metal color algorithms",
                    "âœ… Fixed proportional thumbnail (50% for 2000x2600)",
                    "âœ… White overlay verification with logging",
                    "âœ… SwinIR with transparency support"
                ],
                "thumbnail_method": "Proportional resize (no aggressive cropping)",
                "processing_order": "1.U2Net-Ultra â†’ 2.Enhancement â†’ 3.SwinIR â†’ 4.Ring Holes",
                "edge_detection": "ULTRA PRECISE (Sobel + Guided Filter)",
                "korean_support": "ENHANCED (UTF-8 encoding)",
                "expected_input": "2000x2600 PNG",
                "output_size": "1000x1300",
                "output_format": "PNG with transparency" if keep_transparency and thumbnail.mode == 'RGBA' else "PNG",
                "white_overlay": "AC: 12% (1ì°¨), 15% (2ì°¨) | AB: 5% (1ì°¨), 8% (2ì°¨) + Cool Tone - WITH VERIFICATION",
                "brightness_increased": "8%",
                "contrast_increased": "5%", 
                "sharpness_increased": "1.5-1.6",
                "quality": "95"
            }
        }
        
    except Exception as e:
        logger.error(f"Error: {str(e)}")
        import traceback
        
        return {
            "output": {
                "error": str(e),
                "status": "failed",
                "version": VERSION,
                "traceback": traceback.format_exc()
            }
        }

# RunPod handler
runpod.serverless.start({"handler": handler})
